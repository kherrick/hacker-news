# [Published on 2025-04-29](index.md)

* [2025-04-29, 05:47:04](https://news.ycombinator.com/item?id=43829046) - [Implement Flash Attention Back End in SGLang â€“ Basics and KV Cache](https://hebiao064.github.io/fa3-attn-backend-basic)
