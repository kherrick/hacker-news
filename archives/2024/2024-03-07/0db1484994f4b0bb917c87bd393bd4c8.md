# [Published on 2024-03-07](index.md)

* [2024-03-07, 20:23:46](https://news.ycombinator.com/item?id=39634162) - [Researchers jailbreak AI chatbots with ASCII art](https://www.tomshardware.com/tech-industry/artificial-intelligence/researchers-jailbreak-ai-chatbots-with-ascii-art-artprompt-bypasses-safety-measures-to-unlock-malicious-queries)
