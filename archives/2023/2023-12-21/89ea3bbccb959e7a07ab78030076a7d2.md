# [Published on 2023-12-21](index.md)

* [2023-12-21, 22:31:08](https://news.ycombinator.com/item?id=38728018) - [LLM in a Flash: Efficient Large Language Model Inference with Limited Memory](https://arxiv.org/abs/2312.11514)
