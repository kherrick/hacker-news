<!DOCTYPE html>
<html lang="en" xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <meta
      content="width=device-width, initial-scale=1.0, viewport-fit=cover"
      name="viewport"
    />
    <meta name="description" content="Hacker News" />
    <meta name="theme-color" content="#fff" />
    <title>Hacker News</title>
    <link rel="manifest" href="manifest.json" />
    <link
      href="data:image/x-icon;base64,AAABAAEAAQECAAEAAQA4AAAAFgAAACgAAAABAAAAAgAAAAEAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAAEAAQECAAEAAQA4AAAAFgAAACgAAAABAAAAAgAAAAEAAQAAAAAAAAAAAAAAAAAAAAAAAAAA"
      rel="icon"
      type="image/x-icon"
    />
    <link
      href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAgAAAAIAAQMAAADOtka5AAAAA1BMVEUAAACnej3aAAAANklEQVR42u3BAQEAAACCIP+vbkhAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB8G4IAAAFjdVCkAAAAAElFTkSuQmCC"
      rel="apple-touch-icon"
    />
    <style>
      /*<!--*/
      body {
        color: rgb(25, 25, 25);
        font-family: Verdana, Geneva, sans-serif;
        margin: 0;
      }

      a {
        text-decoration: none;
      }

      a:link,
      a:focus,
      a:hover,
      a:active {
        color: rgb(75, 75, 125);
      }

      a:visited {
        color: rgb(25, 25, 25);
      }

      h1 > a,
      h1 > a:link,
      h1 > a:focus,
      h1 > a:hover,
      h1 > a:active,
      h1 > a:visited,
      h2 > a,
      h2 > a:link,
      h2 > a:focus,
      h2 > a:hover,
      h2 > a:active,
      h2 > a:visited {
        color: rgb(25, 25, 25);
      }

      h1 {
        background-color: rgb(255, 102, 0);
        margin: 0;
        padding: 1rem;
      }

      h2 {
        background-color: rgb(200, 200, 200);
        margin: 1rem 0;
        padding: 0.5rem 0.5rem 0.5rem 1rem;
      }

      #latest > section,
      #archives > section {
        margin: 0 1rem 1rem 1rem;
        padding-bottom: 1rem;
      }

      #latest > section:not(:last-child),
      #archives > section:not(:last-child) {
        border-bottom: 1px dotted rgb(200, 200, 200);
      }

      section > h3 {
        margin: 0 0 0.5rem 0;
      }

      section > h4 {
        font-weight: normal;
        margin: 0 0 0 1rem;
      }

      .descendants-container,
      .points-container {
        align-items: center;
        border-left: 1px solid #333;
        display: inline-flex;
        margin-left: 0.5rem;
        padding-left: 0.5rem;
        text-align: center;
      }

      .points {
        align-items: center;
        display: inline-flex;
        height: 1rem;
        margin-left: 1ch;
        min-width: 3ch;
      }

      .text {
        line-height: 1.5rem;
        margin: 1rem 1rem 0 1rem;
        overflow: auto;
      }

      .text > p:first-child {
        margin-top: 1rem;
      }

      .text > p:last-child {
        margin-bottom: 0;
      }
      /*-->*/
    </style>
  </head>

  <body>
    <main>
      <h1><a href="https://kherrick.github.io/hacker-news/">Hacker News</a></h1>
      <section id="latest">
        <h2>Latest</h2>
        <section id="41458493">
          <h3>
            <a
              class="item"
              href="https://www.ycombinator.com/companies/trellis/jobs/1ypWafM-founding-engineer-full-time-backend-ml-infra"
              >Trellis (YC W24) is hiring eng to build AI workflows for
              unstructured data</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-09-05 @ 17:00:52</span
              ><span class="points-container"
                >Points: <span class="points">1</span></span
              >
            </h4>
          </section>
        </section>
        <section id="41458442">
          <h3>
            <a class="item" href="https://github.com/alastairmccormack/keyutil"
              >A sensible Java key management tool for normal people</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-09-05 @ 16:55:52</span
              ><span class="points-container"
                >Points: <span class="points">13</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=41458442"
                  >Comments</a
                ><span class="descendants">: 6</span></span
              >
            </h4>
          </section>
        </section>
        <section id="41458240">
          <h3>
            <a
              class="item"
              href="https://github.com/cloudflare/serverless-registry"
              >serverless-registry: A Docker registry backed by Workers and
              R2</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-09-05 @ 16:34:51</span
              ><span class="points-container"
                >Points: <span class="points">10</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=41458240"
                  >Comments</a
                ><span class="descendants">: 1</span></span
              >
            </h4>
          </section>
        </section>
        <section id="41458194">
          <h3>
            <a
              class="item"
              href="https://anthonynsimon.com/blog/advice-to-younger-self/"
              >Stuff I would tell my younger self</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-09-05 @ 16:31:01</span
              ><span class="points-container"
                >Points: <span class="points">4</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=41458194"
                  >Comments</a
                ><span class="descendants">: 0</span></span
              >
            </h4>
          </section>
        </section>
        <section id="41458141">
          <h3>
            <a class="item" href="https://kalmia.difuse.io/doc/"
              >Show HN: We built a FOSS documentation CMS with a pretty GUI</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-09-05 @ 16:26:12</span
              ><span class="points-container"
                >Points: <span class="points">8</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=41458141"
                  >Comments</a
                ><span class="descendants">: 0</span></span
              >
            </h4>
            <div class="text">
              <p>
                Recently, we decided to open source it, as we believe others
                might benefit from a lightweight, customizable documentation
                system like this. We're excited to see how the community can
                take it further, contribute, and adapt it to their own needs!
              </p>
            </div>
          </section>
        </section>
        <section id="41458044">
          <h3>
            <a class="item" href="https://github.com/deshraj/claude-memory"
              >Show HN: Claude Memory – Long-term memory for Claude</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-09-05 @ 16:18:13</span
              ><span class="points-container"
                >Points: <span class="points">7</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=41458044"
                  >Comments</a
                ><span class="descendants">: 1</span></span
              >
            </h4>
          </section>
        </section>
        <section id="41457813">
          <h3>
            <a
              class="item"
              href="https://www.smithsonianmag.com/smart-news/workers-uncover-an-underground-chamber-sealed-for-more-than-a-century-near-the-national-mall-180985018/"
              >Workers Uncover Underground Chamber Sealed for over a Century
              Near National Mall</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-09-05 @ 15:56:13</span
              ><span class="points-container"
                >Points: <span class="points">34</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=41457813"
                  >Comments</a
                ><span class="descendants">: 22</span></span
              >
            </h4>
          </section>
        </section>
        <section id="41457633">
          <h3>
            <a class="item" href="https://github.com/Mintplex-Labs/anything-llm"
              >Show HN: AnythingLLM – Open-Source, All-in-One Desktop AI
              Assistant</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-09-05 @ 15:40:45</span
              ><span class="points-container"
                >Points: <span class="points">74</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=41457633"
                  >Comments</a
                ><span class="descendants">: 22</span></span
              >
            </h4>
            <div class="text">
              <p>
                This is Tim from AnythingLLM (<a
                  href="https://github.com/Mintplex-Labs/anything-llm"
                  >https://github.com/Mintplex-Labs/anything-llm</a
                >). AnythingLLM is an open-source desktop assistant that brings
                together RAG (Retrieval-Augmented Generation), agents,
                embeddings, vector databases, and more—all in one seamless
                package.
              </p>
              <p>
                We built AnythingLLM over the last year iterating and iterating
                from user feedback. Our primary mission is to enable people with
                a layperson understanding of AI to be able to use AI with little
                to no setup for either themselves, their jobs, or just to try
                out using AI as an assistant but with *privacy by default*.
              </p>
              <p>
                From these iterations &amp; feedback, we have a couple of key
                learnings I wanted to share:
              </p>
              <p>- "Chat with your docs" solutions are a dime-a-dozen</p>
              <p>
                - Agent frameworks require knowing how to code or are too
                isolated from other tools
              </p>
              <p>
                - Users do not care about benchmarks, only outputs. The magic
                box needs to be magic to them.
              </p>
              <p>
                - Asking Consumers to start a docker container or open a
                terminal is a non-starter for most.
              </p>
              <p>
                - Privacy by default is non-negotiable. Either by personal
                preference or legal constraints
              </p>
              <p>- Everything needs to be in one place</p>
              <p>
                From these ideas, we landed on the current state of AnythingLLM:
              </p>
              <p>
                - Everything in AnythingLLM is private by default, but fully
                customizable for advanced users.
              </p>
              <p>
                - Built-in LLM provider, but can swap at any time to the
                hundreds of other local or cloud LLM providers &amp; models.
              </p>
              <p>
                - Built-in Vector Database, most users don't even know that it
                is there.
              </p>
              <p>
                - Built-in Embedding model, but of course can change if the user
                wants to.
              </p>
              <p>
                - Scrape websites, import Github/GitLab repos, YouTube
                Transcripts, Confluence spaces - all of this is already built in
                for the user.
              </p>
              <p>
                - An entire baked-in agent framework that works seamlessly
                within the app. We even pre-built a handful of agent skills for
                customers. Custom plugins are in the next update and will be
                able to be built with code, or a no-code builder.
              </p>
              <p>
                - All of this just works out of the box in a single installable
                app that can run on any consumer-grade laptop. Everything a user
                does, chats, or configures is stored on the user's device.
                Available for Mac, Windows, and Linux
              </p>
              <p>
                We have been actively maintaining and working on AnythingLLM via
                our open-source repo for a while now and welcome contributors as
                we hopefully launch a Community Hub soon to really proliferate
                users' abilities to add more niche agent skills, data
                connectors, and more.
              </p>
              <p>*But there is even more*</p>
              <p>
                We view the desktop app as a hyper-accessible single-player
                version of AnythingLLM. We publish a Docker image too (<a
                  href="https://hub.docker.com/r/mintplexlabs/anythingllm"
                  >https://hub.docker.com/r/mintplexlabs/anythingllm</a
                >) that supports multi-user management with permissioning so
                that you can easily bring AnythingLLM into an organization with
                all of the same features with minimal headache or lift.
              </p>
              <p>
                The Docker image is for those more adept with a CLI, but being
                able to comfortably go from a single-user to a multi-user
                version of the same familiar app was very important for us.
              </p>
              <p>
                AnythingLLM aims to be more than a UI for LLMs, we are building
                a comprehensive tool to leverage LLMs and all that they can do
                while maintaining user privacy and not needing to be an expert
                on AI to do it.
              </p>
              <p>
                <a href="https://anythingllm.com/">https://anythingllm.com/</a>
              </p>
            </div>
          </section>
        </section>
        <section id="41457331">
          <h3>
            <a
              class="item"
              href="https://deepmind.google/discover/blog/alphaproteo-generates-novel-proteins-for-biology-and-health-research/"
              >AlphaProteo generates novel proteins for biology and health
              research</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-09-05 @ 15:05:49</span
              ><span class="points-container"
                >Points: <span class="points">116</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=41457331"
                  >Comments</a
                ><span class="descendants">: 36</span></span
              >
            </h4>
          </section>
        </section>
        <section id="41456552">
          <h3>
            <a class="item" href="https://news.ycombinator.com/item?id=41456552"
              >Launch HN: Maitai (YC S24) – Self-Optimizing LLM Platform</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-09-05 @ 13:42:43</span
              ><span class="points-container"
                >Points: <span class="points">69</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=41456552"
                  >Comments</a
                ><span class="descendants">: 33</span></span
              >
            </h4>
            <div class="text">
              <a href="https://trymaitai.ai">https://trymaitai.ai</a>). We're
              building an LLM platform that optimizes request routing,
              autocorrects bad responses, and automatically fine-tunes new
              application-specific models with incremental improvements. Here’s
              a demo video:
              <a
                href="https://www.loom.com/share/a2cd9192359840cab5274ccba399bd87?sid=7097fd84-ea85-42cd-9616-84abc1087a56"
                >https://www.loom.com/share/a2cd9192359840cab5274ccba399bd87?...</a
              >.
              <p>
                If you want to try it out, we built a game (<a
                  href="https://maitaistreasure.com"
                  >https://maitaistreasure.com</a
                >) to show how our real-time autocorrections work with
                mission-critical expectations (like never giving financial
                advice). Try and coax the bot to give you the secret phrase in
                its system prompt. If you're the first to crack it, you can
                email us the phrase and win a bounty. Maitai is used to make
                sure the bot always adheres to our expectations, and thus never
                gives up the secret phrase.
              </p>
              <p>
                We built Maitai because getting an LLM app into production and
                maintaining it is a slog. Teams spend most of their time on LLM
                reliability rather than their main product. We experienced this
                ourselves at our previous jobs deploying AI-enabled applications
                for Presto—the vast majority of time was making sure the model
                did what we wanted it to do.
              </p>
              <p>
                For example, one of our customers builds AI ordering agents for
                restaurants. It's crucial that their LLMs return results in a
                predictable, consistent manner throughout the conversation. If
                not, it leads to a poor guest experience and a staff member may
                intervene. At the end of the order conversation, they need to
                ensure that the order cart matches what the customer requested
                before it's submitted to the Point of Sale system. It's common
                for a human-in-the-loop to review critical pieces of information
                like this, but it’s costly to set up such a pipeline and it’s
                difficult to scale. When it's time to send out a receipt and
                payment link, they must first get the customer's consent to
                receive text messages, else they risk fines for violating the
                Telephone Consumer Protection Act. To boot, getting from 0 to 1
                usually relies on inefficient general-purpose models that aren't
                viable at any sort of scale beyond proof of concept.
              </p>
              <p>
                Since reliability is the #1 thing hindering the adoption of LLMs
                in production, we decided to help change that. Here's how it
                works:
              </p>
              <p>
                1. Maitai sits between the client and the LLMs as a super
                lightweight proxy, analyzing traffic to automatically build a
                robust set of expectations for how the LLM should respond.
              </p>
              <p>
                2. The application sends a request to Maitai, and Maitai
                forwards it to the appropriate LLM (user specified, but we'll
                preemptively fallback to a similar model if we notice issues
                with the primary model).
              </p>
              <p>
                3. We intercept the response from the LLM, and evaluate it
                against the expectations we had previously built.
              </p>
              <p>
                4. If we notice that an expectation was not met, we surface a
                fault (Slack, webhook) and can, optionally, substitute the
                faulty response with a clean response to be sent back to the
                client. This check and correction adds about 250ms on average
                right now, and we're working on making it faster.
              </p>
              <p>
                5. We use all of the data from evaluating model responses to
                fine-tune application-specific models. We're working on
                automating this step for passive incremental improvements. We'd
                like to get it to a point where our user's inference step just
                gets better, faster, and cheaper over time without them having
                to do anything.
              </p>
              <p>
                Our hope is that we take on the reliability and resiliency
                problems of the LLMs for our customers, and make it so they can
                focus on domain specific problems instead.
              </p>
              <p>
                We're self-serve (<a href="https://portal.trymaitai.ai"
                  >https://portal.trymaitai.ai</a
                >), and have both Python and Node SDKs that mock OpenAI's for
                quick integration. Users can set their preferences for primary
                and secondary (fallback) models in our Portal, or in code. Right
                now, the expectations we use for real-time evaluations are
                automatically generated, but we manually go through and do some
                pruning before enabling them. Fine-tuning is all done manually
                for now.
              </p>
              <p>
                We charge for platform usage, plus a monthly application fee.
                Customers can bring their own LLM provider API keys, or use ours
                and pay at-cost for what they use. We have contracts with most
                of our current customers, so we are still trying to figure out
                what's right for our pay-as-you-go plan.
              </p>
              <p>
                We securely store requests and responses that go through Maitai,
                as well as derivative data such as evaluation results. This
                information is used for fine-tuning models, accessible only by
                the organization the data belongs to. Data is never shared
                between our users. API keys we manage on behalf of our customers
                are only injected before sending to the LLM provider, and never
                leave our servers otherwise. We're working on SOC2 and HIPAA
                compliance, as well as a self-hosted solution for companies with
                extremely sensitive data privacy requirements.
              </p>
              <p>
                We’d love to get your feedback on what we’re building, or hear
                about your experience building around LLMs!
              </p>
            </div>
          </section>
        </section>
        <section id="41456411">
          <h3>
            <a class="item" href="https://github.com/moritztng/hacker-league"
              >Show HN: Hacker League – Open-Source Rocket League on Linux</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-09-05 @ 13:24:29</span
              ><span class="points-container"
                >Points: <span class="points">144</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=41456411"
                  >Comments</a
                ><span class="descendants">: 70</span></span
              >
            </h4>
          </section>
        </section>
        <section id="41454870">
          <h3>
            <a class="item" href="https://nullprogram.com/blog/2024/09/04/"
              >Giving C++ std:regex a C makeover</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-09-05 @ 09:02:29</span
              ><span class="points-container"
                >Points: <span class="points">68</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=41454870"
                  >Comments</a
                ><span class="descendants">: 42</span></span
              >
            </h4>
          </section>
        </section>
        <section id="41454779">
          <h3>
            <a
              class="item"
              href="https://catfox.life/2024/09/05/porting-systemd-to-musl-libc-powered-linux/"
              >Porting systemd to musl Libc-powered Linux</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-09-05 @ 08:44:58</span
              ><span class="points-container"
                >Points: <span class="points">161</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=41454779"
                  >Comments</a
                ><span class="descendants">: 141</span></span
              >
            </h4>
          </section>
        </section>
        <section id="41453557">
          <h3>
            <a class="item" href="https://github.com/SoptikHa2/desed"
              >Desed: Demystify and debug your sed scripts</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-09-05 @ 04:46:59</span
              ><span class="points-container"
                >Points: <span class="points">128</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=41453557"
                  >Comments</a
                ><span class="descendants">: 48</span></span
              >
            </h4>
          </section>
        </section>
        <section id="41453237">
          <h3>
            <a
              class="item"
              href="https://01-ai.github.io/blog.html?post=en/2024-09-05-A-Small-but-Mighty-LLM-for-Code.md"
              >Yi-Coder: A Small but Mighty LLM for Code</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-09-05 @ 03:38:29</span
              ><span class="points-container"
                >Points: <span class="points">196</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=41453237"
                  >Comments</a
                ><span class="descendants">: 76</span></span
              >
            </h4>
          </section>
        </section>
        <section id="41452962">
          <h3>
            <a
              class="item"
              href="https://www.antipope.org/charlie/blog-static/fiction/accelerando/accelerando.html"
              >Accelerando (2005)</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-09-05 @ 02:33:55</span
              ><span class="points-container"
                >Points: <span class="points">139</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=41452962"
                  >Comments</a
                ><span class="descendants">: 80</span></span
              >
            </h4>
          </section>
        </section>
        <section id="41452339">
          <h3>
            <a class="item" href="https://github.com/harsxv/tinystatus"
              >Tinystatus: A tiny status page generated by a Python script</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-09-05 @ 00:40:25</span
              ><span class="points-container"
                >Points: <span class="points">162</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=41452339"
                  >Comments</a
                ><span class="descendants">: 43</span></span
              >
            </h4>
          </section>
        </section>
        <section id="41451698">
          <h3>
            <a class="item" href="https://github.com/lmnr-ai/lmnr"
              >Show HN: Laminar – Open-Source DataDog + PostHog for LLM Apps,
              Built in Rust</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-09-04 @ 22:52:19</span
              ><span class="points-container"
                >Points: <span class="points">172</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=41451698"
                  >Comments</a
                ><span class="descendants">: 31</span></span
              >
            </h4>
            <div class="text">
              <a href="https://www.lmnr.ai">https://www.lmnr.ai</a>), an
              open-source observability and analytics platform for complex LLM
              apps. It’s designed to be fast, reliable, and scalable. The stack
              is RabbitMQ for message queues, Postgres for storage, Clickhouse
              for analytics, Qdrant for semantic search - all powered by Rust.
              <p>
                How is Laminar different from the swarm of other “LLM
                observability” platforms?
              </p>
              <p>
                On the observability part, we’re focused on handling full
                execution traces, not just LLM calls. We built a Rust ingestor
                for OpenTelemetry (Otel) spans with GenAI semantic conventions.
                As LLM apps get more complex (think Agents with hundreds of LLM
                and function calls, or complex RAG pipelines), full tracing is
                critical. With Otel spans, we can: 1. Cover the entire execution
                trace. 2. Keep the platform future-proof 3. Leverage an amazing
                OpenLLMetry (<a href="https://github.com/traceloop/openllmetry"
                  >https://github.com/traceloop/openllmetry</a
                >), open-source package for span production.
              </p>
              <p>
                The key difference is that we tie text analytics directly to
                execution traces. Rich text data makes LLM traces unique, so we
                let you track “semantic metrics” (like what your AI agent is
                actually saying) and connect those metrics to where they happen
                in the trace. If you want to know if your AI drive-through agent
                made an upsell, you can design an LLM extraction pipeline in our
                builder (more on it later), host it on Laminar, and handle
                everything from event requests to output logging. Processing
                requests simply come as events in the Otel span.
              </p>
              <p>
                We think it’s a win to separate core app logic from LLM event
                processing. Most devs don’t want to manage background queues for
                LLM analytics processing but still want insights into how their
                Agents or RAGs are working.
              </p>
              <p>
                Our Pipeline Builder uses graph UI where nodes are LLM and util
                functions, and edges showing data flow. We built a custom task
                execution engine with support of parallel branch executions,
                cycles and branches (it’s overkill for simple pipelines, but
                it’s extremely cool and we’ve spent a lot of time designing a
                robust engine). You can also call pipelines directly as API
                endpoints. We found them to be extremely useful for iterating on
                and separating LLM logic. Laminar also traces pipeline directly,
                which removes the overhead of sending large outputs over the
                network.
              </p>
              <p>
                One thing missing from all LLM observability platforms right now
                is an adequate search over traces. We’re attacking this problem
                by indexing each span in a vector DB and performing hybrid
                search at query time. This feature is still in beta, but we
                think it’s gonna be crucial part of our platform going forward.
              </p>
              <p>
                We also support evaluations. We loved the “run everything
                locally, send results to a server” approach from Braintrust and
                Weights &amp; Biases, so we did that too: a simple SDK and nice
                dashboards to track everything. Evals are still early, but we’re
                pushing hard on them.
              </p>
              <p>
                Our goal is to make Laminar the Supabase for LLMOps - the go-to
                open-source comprehensive platform for all things LLMs / GenAI.
                In it’s current shape, Laminar is just few weeks old and
                developing rapidly, we’d love any feedback or for you to give
                Laminar a try in your LLM projects!
              </p>
            </div>
          </section>
        </section>
        <section id="41451431">
          <h3>
            <a
              class="item"
              href="https://www.viksnewsletter.com/p/origami-inspired-phased-arrays"
              >Origami-Inspired Phased Arrays Are Reshaping the Future of
              Antennas</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-09-04 @ 22:13:40</span
              ><span class="points-container"
                >Points: <span class="points">103</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=41451431"
                  >Comments</a
                ><span class="descendants">: 6</span></span
              >
            </h4>
          </section>
        </section>
        <section id="41448439">
          <h3>
            <a
              class="item"
              href="https://github.com/Ligo-Biosciences/AlphaFold3"
              >Show HN: An open-source implementation of AlphaFold3</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-09-04 @ 17:44:17</span
              ><span class="points-container"
                >Points: <span class="points">286</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=41448439"
                  >Comments</a
                ><span class="descendants">: 32</span></span
              >
            </h4>
            <div class="text">
              <p>
                Google DeepMind and their new startup Isomorphic Labs, are
                expanding into drug discovery. They developed AlphaFold3 as
                their model to accelerate drug discovery and create demand from
                big pharma. They already signed Novartis and Eli Lilly for $3
                billion - Google’s becoming a pharma company! (<a
                  href="https://www.isomorphiclabs.com/articles/isomorphic-labs-kicks-off-2024-with-two-pharmaceutical-collaborations"
                  >https://www.isomorphiclabs.com/articles/isomorphic-labs-kick...</a
                >)
              </p>
              <p>
                AlphaFold3 is a biomolecular structure prediction model that can
                do three main things: (1) Predict the structure of proteins; (2)
                Predict the structure of drug-protein interactions; (3) Predict
                nucleic acid - protein complex structure.
              </p>
              <p>
                AlphaFold3 is incredibly important for science because it vastly
                accelerates the mapping of protein structures. It takes one PhD
                student their entire PhD to do one structure. With AlphaFold3,
                you get a prediction in minutes on par with experimental
                accuracy.
              </p>
              <p>
                There’s just one problem: when DeepMind published AlphaFold3 in
                May (<a
                  href="https://www.nature.com/articles/s41586-024-07487-w"
                  >https://www.nature.com/articles/s41586-024-07487-w</a
                >), there was no code. This brought up questions about
                reproducibility (<a
                  href="https://www.nature.com/articles/d41586-024-01463-0"
                  >https://www.nature.com/articles/d41586-024-01463-0</a
                >) as well as complaints from the scientific community (<a
                  href="https://undark.org/2024/06/06/opinion-alphafold-3-open-source/"
                  >https://undark.org/2024/06/06/opinion-alphafold-3-open-sourc...</a
                >).
              </p>
              <p>
                AlphaFold3 is a fundamental advance in structure modeling
                technology that the entire biotech industry deserves to be able
                to reap the benefits from. Its applications are vast, including:
              </p>
              <p>
                - CRISPR gene editing technologies, where scientists can see
                exactly how the DNA interacts with the scissor Cas protein;
              </p>
              <p>
                - Cancer research - predicting how a potential drug binds to the
                cancer target. One of the highlights in DeepMind’s paper is the
                prediction of a clinical KRAS inhibitor in complex with its
                target.
              </p>
              <p>
                - Antibody / nanobody to target predictions. AlphaFold3 improves
                accuracy on this class of molecules 2 fold compared to the next
                best tool.
              </p>
              <p>
                Unfortunately, no companies can use it since it is under a
                non-commercial license!
              </p>
              <p>
                Today we are releasing the full model trained on single chain
                proteins (capability 1 above), with the other two capabilities
                to be trained and released soon. We also include the training
                code. Weights will be released once training and benchmarking is
                complete. We wanted this to be truly open source so we used the
                Apache 2.0 license.
              </p>
              <p>
                Deepmind published the full structure of the model, along with
                each components’ pseudocode in their paper. We translated this
                fully into PyTorch, which required more reverse engineering than
                we thought!
              </p>
              <p>
                When building the initial version, we discovered multiple issues
                in DeepMind’s paper that would interfere with the training - we
                think the deep learning community might find these especially
                interesting. (Diffusion folks, we would love feedback on this!)
                These include:
              </p>
              <p>
                - MSE loss scaling differs from Karras et al. (2022). The
                weighting provided in the paper does not downweigh the loss at
                high noise levels.
              </p>
              <p>
                - Omission of residual layers in the paper - we add these back
                and see benefits in gradient flow and convergence. Anyone have
                any idea why Deepmind may have omitted the residual connections
                in the DiT blocks?
              </p>
              <p>
                - The MSA module, in its current form, has dead layers. The last
                pair weighted averaging and transition layers cannot contribute
                to the pair representation, hence no grads. We swap the order to
                the one in the ExtraMsaStack in AlphaFold2. An alternative
                solution would be to use weight sharing, but whether this is
                done is ambiguous in the paper.
              </p>
              <p>
                More about those issues here:
                <a href="https://github.com/Ligo-Biosciences/AlphaFold3"
                  >https://github.com/Ligo-Biosciences/AlphaFold3</a
                >
              </p>
              <p>
                How this came about: we are building Ligo (YC S24), where we are
                using ideas from AlphaFold3 for enzyme design. We thought open
                sourcing it was a nice side quest to benefit the community.
              </p>
              <p>
                For those on Twitter, there was a good thread a few days ago
                that has more information:
                <a
                  href="https://twitter.com/ArdaGoreci/status/1830744265007480934"
                  >https://twitter.com/ArdaGoreci/status/1830744265007480934</a
                >.
              </p>
              <p>
                A few shoutouts: A huge thanks to OpenFold for pioneering the
                previous open source implementation of AlphaFold We did a lot of
                our early prototyping with proteinFlow developed by Lisa at
                AdaptyvBio we also look forward to partnering with them to bring
                you the next versions! We are also partnering with Basecamp
                Research to supply this model with the best sequence data known
                to science. Matthew Clark (<a href="https://batisio.co.uk"
                  >https://batisio.co.uk</a
                >) for his amazing animations!
              </p>
              <p>
                We’re around to answer questions and look forward to hearing
                from you!
              </p>
            </div>
          </section>
        </section>
        <section id="41448022">
          <h3>
            <a class="item" href="https://dynamicland.org/">Dynamicland 2024</a>
          </h3>
          <section>
            <h4>
              <span>2024-09-04 @ 17:02:14</span
              ><span class="points-container"
                >Points: <span class="points">535</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=41448022"
                  >Comments</a
                ><span class="descendants">: 164</span></span
              >
            </h4>
          </section>
        </section>
        <section id="41447758">
          <h3>
            <a
              class="item"
              href="https://storage.courtlistener.com/recap/gov.uscourts.ca2.60988/gov.uscourts.ca2.60988.306.1.pdf"
              >The Internet Archive has lost its appeal in Hachette vs. Internet
              Archive</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-09-04 @ 16:41:50</span
              ><span class="points-container"
                >Points: <span class="points">905</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=41447758"
                  >Comments</a
                ><span class="descendants">: 677</span></span
              >
            </h4>
          </section>
        </section>
        <section id="41447515">
          <h3>
            <a
              class="item"
              href="https://www.quantamagazine.org/the-first-nuclear-clock-will-test-if-fundamental-constants-change-20240904/"
              >The first nuclear clock will test if fundamental constants
              change</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-09-04 @ 16:23:34</span
              ><span class="points-container"
                >Points: <span class="points">261</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=41447515"
                  >Comments</a
                ><span class="descendants">: 163</span></span
              >
            </h4>
          </section>
        </section>
        <section id="41432625">
          <h3>
            <a
              class="item"
              href="https://www.sctheblog.com/blog/hair-software-rasterize/"
              >Software Rasterizing Hair</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-09-03 @ 08:30:32</span
              ><span class="points-container"
                >Points: <span class="points">50</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=41432625"
                  >Comments</a
                ><span class="descendants">: 13</span></span
              >
            </h4>
          </section>
        </section>
        <section id="41432197">
          <h3>
            <a
              class="item"
              href="https://www.semianalysis.com/p/the-memory-wall"
              >The Memory Wall: Past, Present, and Future of DRAM</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-09-03 @ 07:19:26</span
              ><span class="points-container"
                >Points: <span class="points">18</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=41432197"
                  >Comments</a
                ><span class="descendants">: 1</span></span
              >
            </h4>
          </section>
        </section>
        <section id="41432101">
          <h3>
            <a class="item" href="https://johnholdun.com/apis/"
              >The Elements of APIs (2021)</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-09-03 @ 07:04:56</span
              ><span class="points-container"
                >Points: <span class="points">103</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=41432101"
                  >Comments</a
                ><span class="descendants">: 18</span></span
              >
            </h4>
          </section>
        </section>
        <section id="41431888">
          <h3>
            <a class="item" href="https://zeppelin.apache.org/"
              >Apache Zeppelin</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-09-03 @ 06:29:13</span
              ><span class="points-container"
                >Points: <span class="points">39</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=41431888"
                  >Comments</a
                ><span class="descendants">: 13</span></span
              >
            </h4>
          </section>
        </section>
        <section id="41426466">
          <h3>
            <a
              class="item"
              href="https://systemsapproach.org/2024/08/19/how-the-hourglass-won/"
              >How the Hourglass Won</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-09-02 @ 15:50:48</span
              ><span class="points-container"
                >Points: <span class="points">82</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=41426466"
                  >Comments</a
                ><span class="descendants">: 39</span></span
              >
            </h4>
          </section>
        </section>
        <section id="41423095">
          <h3>
            <a
              class="item"
              href="https://hakaimagazine.com/features/here-a-bee-there-a-bee-everywhere-a-wild-bee/"
              >Here a Bee, There a Bee, Everywhere a Wild Bee</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-09-02 @ 06:30:47</span
              ><span class="points-container"
                >Points: <span class="points">64</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=41423095"
                  >Comments</a
                ><span class="descendants">: 44</span></span
              >
            </h4>
          </section>
        </section>
        <section id="41420672">
          <h3>
            <a
              class="item"
              href="https://leejo.github.io/2024/09/01/off_by_one/"
              >A Real Life Off-by-One Error</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-09-01 @ 21:47:42</span
              ><span class="points-container"
                >Points: <span class="points">280</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=41420672"
                  >Comments</a
                ><span class="descendants">: 106</span></span
              >
            </h4>
          </section>
        </section>
      </section>
      <section id="archives">
        <h2>
          <a
            href="https://github.com/kherrick/hacker-news/blob/main/archives/index.md"
            >Archives</a
          >
        </h2>
        <section>
          <h3>
            <a
              href="https://github.com/kherrick/hacker-news/blob/main/archives/2024/index.md"
              >2024</a
            >
          </h3>
        </section>
        <section>
          <h3>
            <a
              href="https://github.com/kherrick/hacker-news/blob/main/archives/2023/index.md"
              >2023</a
            >
          </h3>
        </section>
        <section>
          <h3>
            <a
              href="https://github.com/kherrick/hacker-news/blob/main/archives/2022/index.md"
              >2022</a
            >
          </h3>
        </section>
      </section>
    </main>
    <script type="module">
      import { buildDescendants } from "./lib/build-html-descendants.js";
      import { buildNextItem } from "./lib/build-html-next-item.js";
      import { getNextDateTime } from "./lib/date-time.js";

      const updateSectionById = (id) =>
        fetch(`https://hacker-news.firebaseio.com/v0/item/${id}.json`).then(
          (result) =>
            result.json().then(({ descendants, id, score, text, type }) => {
              const currentItem = document.getElementById(id);

              if (score) {
                currentItem.querySelector(".points").textContent = score;
              }

              if (descendants && (type === "poll" || type === "story")) {
                const currentDescendants =
                  currentItem.querySelector(".descendants");

                if (currentDescendants) {
                  currentDescendants.textContent = `: ${descendants}`;
                } else {
                  const comments = buildDescendants(
                    document,
                    descendants,
                    `https://news.ycombinator.com/item?id=${id}`
                  );

                  currentItem.querySelector("h4").appendChild(comments);
                }
              }

              if (text) {
                const currentText = currentItem.querySelector(".text");

                if (currentText) {
                  currentText.innerHTML = text.replace(/\0/g, "");
                } else {
                  const content = document.createElement("div");
                  content.innerHTML = text.replace(/\0/g, "");
                  content.setAttribute("class", "text");

                  currentItem.appendChild(content);
                }
              }
            })
        );

      class UpdateQueue {
        constructor() {
          this._ids = [];
          this._isUpdating = false;
        }

        addItemById(id) {
          this._ids.push(id);
        }

        async flush() {
          const id = this._ids.shift();

          if (id) {
            this._isUpdating = true;

            await updateSectionById(id);
            await this.flush();
          } else {
            this._isUpdating = false;

            setTimeout(async () => {
              if (!this._isUpdating && this._ids && this._ids.length) {
                await this.flush();
              }
            }, 0);
          }
        }
      }

      // get latest data
      const latestSection = document.getElementById("latest");

      for (let item of latestSection.querySelectorAll("section[id]")) {
        updateSectionById(item.getAttribute("id"));
      }

      if ("IntersectionObserver" in window) {
        window.hackerNewsState = { index: [], nextTimeIndex: -1 };

        const addNewsItem = async (newsItem, queue) => {
          try {
            const { date, time, itemComments, itemTitle, itemLink } = newsItem;
            const section = await buildNextItem({
              document,
              dateTime: `${date}, ${time}`,
              itemComments,
              itemLink,
              itemTitle: new DOMParser().parseFromString(
                itemTitle.replace(/\\/g, ""),
                "text/html"
              ).documentElement.textContent,
              fetchItemDetails: false,
            });

            // display loading indicator for section
            section.querySelector(".points-container").innerHTML =
              'Points: <span class="points"><img style="height: 100%;" src="lib/images/loading.svg" /></span>';

            const id = section.getAttribute("id");
            if (!document.getElementById(id)) {
              document.getElementById("latest").appendChild(section);

              queue.addItemById(id);
            }
          } catch (error) {}
        };

        const buildArchiveIndex = async (lastDateTime) => {
          const nextDate = lastDateTime.slice(0, 10);
          const nextYear = nextDate.slice(0, 4);

          return (
            await (
              await fetch(
                `https://raw.githubusercontent.com/kherrick/hacker-news/main/archives/${nextYear}/${nextDate}/index.md`
              )
            ).text()
          )
            .split("\n")
            .filter((line) => line.match(new RegExp("^\\* \\[")))
            .map((line) => {
              const segment = line.replace("* ", "").split("](");
              const pubDate = segment[0].slice(1);

              const itemComments = segment[1].split(") - [")[0];
              const itemTitle = segment[1].split(") - [")[1];
              const itemLink = segment[2].slice(0, -1);
              const date = pubDate.slice(0, 10);
              const time = pubDate.slice(-8);

              return {
                date,
                itemComments,
                itemLink,
                itemTitle,
                time,
              };
            });
        };

        const handleIntersectingEntry = async (entry, queue) => {
          if (entry.isIntersecting) {
            const lastDateTime = document
              .getElementById("latest")
              .querySelector(
                "section:last-child > section > h4 > span"
              ).textContent;

            const nextDateTime = getNextDateTime(lastDateTime ?? "", -1);
            const archiveIndex = await buildArchiveIndex(nextDateTime);
            const nextTimeIndex = archiveIndex.findIndex(
              ({ time }) => time === nextDateTime.slice(-8)
            );

            const handleIndexUpdate = (index, existingIndexValues = []) => {
              index.forEach((i) => {
                existingIndexValues.push(i);
              });
              return existingIndexValues;
            };

            window.hackerNewsState = {
              index: handleIndexUpdate(
                archiveIndex,
                window.hackerNewsState.index
              ),
              nextTimeIndex,
            };

            let currentTimeIndex = nextTimeIndex + 1;
            const items = Object.values(window.hackerNewsState.index);
            for (let item of items) {
              if (currentTimeIndex < window.hackerNewsState.index.length) {
                addNewsItem(items[currentTimeIndex], queue);

                currentTimeIndex = currentTimeIndex + 1;
              }
            }

            queue.flush();
          }
        };

        const archives = document.getElementById("archives");
        const archivesObserver = new IntersectionObserver(
          (entries) => {
            const queue = new UpdateQueue();

            entries.forEach((entry) => handleIntersectingEntry(entry, queue));
          },
          {
            root: null,
            rootMargin: "0px",
            threshold: 0,
          }
        );

        archivesObserver.observe(archives);

        let latestSectionsExpanded = true;
        const handleLatestHeaderClick = () => {
          latestSectionsExpanded = !latestSectionsExpanded;

          if (latestSectionsExpanded) {
            archivesObserver.observe(archives);
          } else {
            archivesObserver.disconnect(archives);
          }

          for (let section of document.querySelectorAll("#latest > section")) {
            section.style.display = latestSectionsExpanded ? "block" : "none";
          }
        };

        const latestHeader = document.querySelector("#latest > h2");
        latestHeader.style.cursor = "pointer";
        latestHeader.addEventListener("click", handleLatestHeaderClick);
      }
    </script>
    <script type="module">
      import { Workbox } from "https://storage.googleapis.com/workbox-cdn/releases/6.4.1/workbox-window.prod.mjs";

      if ("serviceWorker" in navigator) {
        const base = document.querySelector("base");
        const serviceWorkerPath = `${
          base ? base.href.replace(/\/$/, "") : ""
        }/service-worker.js`;

        const wb = new Workbox(serviceWorkerPath);

        // setup event listeners
        wb.addEventListener("waiting", (event) => {
          wb.addEventListener("controlling", () => {
            window.location.reload();
          });

          wb.messageSkipWaiting();
        });

        wb.register();
      }
    </script>
  </body>
</html>
