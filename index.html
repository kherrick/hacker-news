<!DOCTYPE html>
<html lang="en" xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <meta
      content="width=device-width, initial-scale=1.0, viewport-fit=cover"
      name="viewport"
    />
    <meta name="description" content="Hacker News" />
    <meta name="theme-color" content="#fff" />
    <title>Hacker News</title>
    <link rel="manifest" href="manifest.json" />
    <link
      href="data:image/x-icon;base64,AAABAAEAAQECAAEAAQA4AAAAFgAAACgAAAABAAAAAgAAAAEAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAAEAAQECAAEAAQA4AAAAFgAAACgAAAABAAAAAgAAAAEAAQAAAAAAAAAAAAAAAAAAAAAAAAAA"
      rel="icon"
      type="image/x-icon"
    />
    <link
      href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAgAAAAIAAQMAAADOtka5AAAAA1BMVEUAAACnej3aAAAANklEQVR42u3BAQEAAACCIP+vbkhAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB8G4IAAAFjdVCkAAAAAElFTkSuQmCC"
      rel="apple-touch-icon"
    />
    <style>
      /*<!--*/
      body {
        color: rgb(25, 25, 25);
        font-family: Verdana, Geneva, sans-serif;
        margin: 0;
      }

      a {
        text-decoration: none;
      }

      a:link,
      a:focus,
      a:hover,
      a:active {
        color: rgb(75, 75, 125);
      }

      a:visited {
        color: rgb(25, 25, 25);
      }

      h1 > a,
      h1 > a:link,
      h1 > a:focus,
      h1 > a:hover,
      h1 > a:active,
      h1 > a:visited,
      h2 > a,
      h2 > a:link,
      h2 > a:focus,
      h2 > a:hover,
      h2 > a:active,
      h2 > a:visited {
        color: rgb(25, 25, 25);
      }

      h1 {
        background-color: rgb(255, 102, 0);
        margin: 0;
        padding: 1rem;
      }

      h2 {
        background-color: rgb(200, 200, 200);
        margin: 1rem 0;
        padding: 0.5rem 0.5rem 0.5rem 1rem;
      }

      #latest > section,
      #archives > section {
        margin: 0 1rem 1rem 1rem;
        padding-bottom: 1rem;
      }

      #latest > section:not(:last-child),
      #archives > section:not(:last-child) {
        border-bottom: 1px dotted rgb(200, 200, 200);
      }

      section > h3 {
        margin: 0 0 0.5rem 0;
      }

      section > h4 {
        font-weight: normal;
        margin: 0 0 0 1rem;
      }

      .descendants-container,
      .points-container {
        align-items: center;
        border-left: 1px solid #333;
        display: inline-flex;
        margin-left: 0.5rem;
        padding-left: 0.5rem;
        text-align: center;
      }

      .points {
        align-items: center;
        display: inline-flex;
        height: 1rem;
        margin-left: 1ch;
        min-width: 3ch;
      }

      .text {
        line-height: 1.5rem;
        margin: 1rem 1rem 0 1rem;
        overflow: auto;
      }

      .text > p:first-child {
        margin-top: 1rem;
      }

      .text > p:last-child {
        margin-bottom: 0;
      }
      /*-->*/
    </style>
  </head>

  <body>
    <main>
      <h1><a href="https://kherrick.github.io/hacker-news/">Hacker News</a></h1>
      <section id="latest">
        <h2>Latest</h2>
        <section id="42183115">
          <h3>
            <a
              class="item"
              href="https://www.nakedcapitalism.com/2024/11/will-online-age-verification-be-the-trojan-horse-for-mass-rollout-of-digital-id.html"
              >Online Age Verification as Trojan Horse for the Mass Rollout of
              Digital IDs?</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-11-19 @ 13:21:01</span
              ><span class="points-container"
                >Points: <span class="points">33</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=42183115"
                  >Comments</a
                ><span class="descendants">: 13</span></span
              >
            </h4>
          </section>
        </section>
        <section id="42182519">
          <h3>
            <a
              class="item"
              href="https://tech.marksblogg.com/osm-mvt-vector-tiles.html"
              >OpenStreetMap's New Vector Tiles</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-11-19 @ 12:03:02</span
              ><span class="points-container"
                >Points: <span class="points">46</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=42182519"
                  >Comments</a
                ><span class="descendants">: 7</span></span
              >
            </h4>
          </section>
        </section>
        <section id="42182503">
          <h3>
            <a class="item" href="https://news.ycombinator.com/item?id=42182503"
              >Expand.ai (YC S24) Is Hiring a Founding Engineer to Turn the Web
              into an API</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-11-19 @ 12:01:01</span
              ><span class="points-container"
                >Points: <span class="points">1</span></span
              >
            </h4>
            <div class="text">
              <p>---</p>
              <p>
                We’re building out the early engineering team of expand.ai,
                where we’re (a) solving a problem the world urgently needs to be
                solved, that is (b) one of the most challenging problems in
                technology, (c) alongside a team of exceptional engineers (d)
                offering you the chance to have a massive impact, (e) while
                having fun (f) and be reward accordingly.
              </p>
              <p>(a) Problem</p>
              <p>
                While LLMs are democratizing intelligence, access to data
                remains a huge bottleneck. We're changing that by building
                state-of-the-art web extraction agents that structure millions
                of websites—one at a time.
              </p>
              <p>
                Scraping is not new. Folks have written XPaths, manual beautiful
                soup scripts, etc.
              </p>
              <p>However, two things changed:</p>
              <p>
                1. Scraping is needed even more than before. Almost any AI
                application needs access to some data from the internet. 2.
                We’re in the post-LLM era. While LLMs are too expensive to run
                over the internet, they enable previously impossible
                capabilities.
              </p>
              <p>
                That’s why we’re on a mission to build a reliable data layer for
                the web.
              </p>
              <p>
                When we soft launched in September, we got an insane amount of
                interest, with over 170 demos booked in 24 hours. This confirms
                how much of a problem this is for folks.
              </p>
              <p>
                We’re luckily not alone on this mission and have backing from
                the best: YCombinator, Guillermo Rauch (CEO, Vercel), Swyx
                (Founder, smol ai), Sarah Guo (Conviction Embed), Alana Goyal
                (basecase capital), Max Claussen (system.one), Ellen Chisa,
                Charly Poly, … and many more!
              </p>
              <p>(b) Tech challenges</p>
              <p>
                We have collectively coded for over 20 years and never faced
                this difficulty of a technical challenge. We’re building a
                highly dynamic system that needs to deal with the
                undeterministic nature of the internet, at scale.
              </p>
              <p>Some of the challenges we’re tackling:</p>
              <p>
                1. Building a fair system across multiple tenants (noisy
                neighbors) 2. Quickly scaling up and down web agent and AI infra
                depending on demand 3. Coordinate thousands of web agents that
                concurrently try to extract data 4. High-quality data pipelines
                to make sure our clients get only the correct data. We care a
                lot about reliability and correctness. 5. Scaling our system to
                millions of websites 6. Our agents need to be able to perform
                actions on websites - not all of them directly show the
                information we need to get! 7. As this is such new territory, a
                lot of the tooling we need doesn’t exist yet and we have to
                build it ourselves.
              </p>
              <p>What is our answer to these? How will we win?</p>
              <p>In short - good old software engineering.</p>
              <p>Longer Answer:</p>
              <p>
                - We’re making heavy use of [Effect](<a
                  href="https://effect.website/"
                  >https://effect.website/</a
                >), which allows us to gain as much control as you possibly can
                in such an undeterministic environment. Also, it will enable us
                to represent complex agentic workflows while keeping a deep
                level of observability. - We’re making use of the latest
                advances in AI, including training our own models and using the
                latest insights from research. - It took us a while to arrive at
                the current system design, and we certainly don’t have all the
                answers yet, but we have iterated on our main architecture
                multiple times, which allows us to represent very complex
                workflows.
              </p>
              <p>(c) Team</p>
              <p>We’re a nimble team of 2 right now.</p>
              <p>
                1. [Tim Suchanek](<a href="https://github.com/timsuchanek"
                  >https://github.com/timsuchanek</a
                >) (Founder) 1. Tim was the first engineer at Prisma, where he
                led the development of several tools, including the GraphQL
                Playground and Prisma ORM, which are now used by millions of
                developers. 2. Tim then founded Stellate, a GraphQL API
                management company that handled billions of monthly requests
                from customers like Nasa, Puma, and Priceline. Stellate was
                acquired by Shopify in 2024. 3. Tim does Brazilian Jiu-Jitsu
                (BJJ) as a hobby and holds a blue belt in it. 2. [Tylor
                Steinberger](<a href="https://github.com/TylorS"
                  >https://github.com/TylorS</a
                >) (Founding Engineer) 1. Tylor joined the Cycle.js project
                early on, building out major parts of the system. 2. After a
                career in startup tech, Tylor last led the frontend development
                at Seasoned, where he implemented one of the [first functional
                full-stack frameworks](<a href="https://github.com/TylorS/typed"
                  >https://github.com/TylorS/typed</a
                >), which is still used today. 3. As a hobby, Tylor implements
                his own programming language and always thinks about how to push
                the boundaries of programming. 3. You 1. What kind of
                engineering profile are we looking for? You’re a good fit if you
                1. Are backend-focused and have worked on a difficult project
                before 2. Have a machine-learning background and have built data
                pipelines before 3. Have worked on scalable infrastructure 4.
                Have a distributed systems background 5. If none of the above
                matches, but you think you’re excellent - apply nevertheless!
              </p>
              <p>(d) Impact</p>
              <p>
                While there are established use cases for web scraping, such as
                e-commerce cataloging, extracting accurate data from websites is
                becoming a crucial building block for AI agents and supporting
                better decision-making. Transforming the internet into a
                queryable database will emerge a whole new economy, enabling
                more informed choices across various sectors. Our mission is to
                power that economy and facilitate improved decision-making
                processes. The demand for our system is undeniably strong, with
                thousands of people reaching out to gain access.
              </p>
              <p>(e) Fun</p>
              <p>
                As you can probably already read, we try not to take ourselves
                too seriously. We’re working very hard at [expand.ai](<a
                  href="http://expand.ai"
                  >http://expand.ai</a
                >), and it’s just super important that we’re all enjoying our
                work and each other's company. Yes, part of it also includes
                edgy (but respectful) jokes.
              </p>
              <p>
                One thing that makes it much more fun is being together in
                person! We have a nice, cozy office in Dogpatch, San Francisco.
                Eating together, doing whiteboard sessions together, hacking
                together—it’s just so much more fun to be in person!
              </p>
              <p>
                That’s why: **This is an in-person position only. Please don’t
                apply if you can’t move to SF.**
              </p>
              <p>(f) Compensation</p>
              <p>
                We’re putting a lot of love and energy into this project, so
                while having a massive impact, we also want you and us to be
                able to capture some of the value we create.
              </p>
              <p>
                We have a generous equity package, especially for the first few
                folks!
              </p>
              <p>
                If you want to grow, push your limits and are also excited about
                solving hard technical problems, please reach out to
                foundingengineer@expand.ai.
              </p>
            </div>
          </section>
        </section>
        <section id="42182146">
          <h3>
            <a class="item" href="https://github.com/frectonz/pglite-fusion"
              >Show HN: Embed an SQLite database in your PostgreSQL table</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-11-19 @ 11:02:32</span
              ><span class="points-container"
                >Points: <span class="points">12</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=42182146"
                  >Comments</a
                ><span class="descendants">: 6</span></span
              >
            </h4>
            <div class="text">
              <p>
                In addition to the PostgreSQL `SQLITE` type, pglite-fusion
                provides the `query_sqlite`` function for querying SQLite
                databases and the `execute_sqlite` function for updating them.
                Additional functions are listed in the project’s README.
              </p>
              <p>
                The pglite-fusion extension is written in Rust using the pgrx
                framework [1].
              </p>
              <p>----</p>
              <p>Implementation Details</p>
              <p>
                The PostgreSQL `SQLITE` type is stored as a CBOR-encoded
                `Vec&lt;u8&gt;`. When a query is made, this `Vec&lt;u8&gt;` is
                written to a random file in the `/tmp` directory. SQLite then
                loads the file, performs the query, and returns the result as a
                table containing a single row with an array of JSON-encoded
                values.
              </p>
              <p>
                The `execute_sqlite` function follows a similar process.
                However, instead of returning query results, it returns the
                contents of the SQLite file (stored in `/tmp`) as a new `SQLITE`
                instance.
              </p>
              <p>
                [1]
                <a href="https://github.com/pgcentralfoundation/pgrx"
                  >https://github.com/pgcentralfoundation/pgrx</a
                >
              </p>
            </div>
          </section>
        </section>
        <section id="42181467">
          <h3>
            <a
              class="item"
              href="https://www.vox.com/2015/3/4/8147377/mp3-compressed-ghosts"
              >Listen to what gets lost when an MP3 is made (2015)</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-11-19 @ 09:23:43</span
              ><span class="points-container"
                >Points: <span class="points">101</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=42181467"
                  >Comments</a
                ><span class="descendants">: 56</span></span
              >
            </h4>
          </section>
        </section>
        <section id="42181432">
          <h3>
            <a
              class="item"
              href="https://pagedout.institute/download/PagedOut_005.pdf"
              >Paged Out #5 – hacker zine release [pdf]</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-11-19 @ 09:18:57</span
              ><span class="points-container"
                >Points: <span class="points">20</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=42181432"
                  >Comments</a
                ><span class="descendants">: 4</span></span
              >
            </h4>
          </section>
        </section>
        <section id="42181411">
          <h3>
            <a
              class="item"
              href="https://www.bloomberg.com/news/articles/2024-11-18/hong-kong-to-sentence-45-activists-in-biggest-security-law-case"
              >Hong Kong Jails Benny Tai for 10 Years in Longest Security Law
              Sentence</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-11-19 @ 09:15:28</span
              ><span class="points-container"
                >Points: <span class="points">59</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=42181411"
                  >Comments</a
                ><span class="descendants">: 8</span></span
              >
            </h4>
          </section>
        </section>
        <section id="42180763">
          <h3>
            <a
              class="item"
              href="https://www.digitalocean.com/community/tutorials/pytorch-101-understanding-graphs-and-automatic-differentiation"
              >PyTorch 101: Understanding Graphs, Automatic Differentiation and
              Autograd</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-11-19 @ 07:13:01</span
              ><span class="points-container"
                >Points: <span class="points">52</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=42180763"
                  >Comments</a
                ><span class="descendants">: 2</span></span
              >
            </h4>
          </section>
        </section>
        <section id="42180516">
          <h3>
            <a
              class="item"
              href="https://raw.sh/posts/easy_reward_model_inference"
              >Batched reward model inference and Best-of-N sampling</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-11-19 @ 06:19:48</span
              ><span class="points-container"
                >Points: <span class="points">19</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=42180516"
                  >Comments</a
                ><span class="descendants">: 0</span></span
              >
            </h4>
          </section>
        </section>
        <section id="42179969">
          <h3>
            <a class="item" href="https://arxiv.org/abs/2411.10466"
              >Iumenta: A generic framework for animal digital twins</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-11-19 @ 03:54:00</span
              ><span class="points-container"
                >Points: <span class="points">18</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=42179969"
                  >Comments</a
                ><span class="descendants">: 8</span></span
              >
            </h4>
          </section>
        </section>
        <section id="42179773">
          <h3>
            <a class="item" href="https://github.com/ssoready/hyrumtoken"
              >Hyrumtoken: A Go package to encrypt pagination tokens</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-11-19 @ 03:12:12</span
              ><span class="points-container"
                >Points: <span class="points">60</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=42179773"
                  >Comments</a
                ><span class="descendants">: 39</span></span
              >
            </h4>
          </section>
        </section>
        <section id="42179541">
          <h3>
            <a class="item" href="https://github.com/charmbracelet/sequin"
              >Sequin: A powerful little tool for inspecting ANSI escape
              sequences</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-11-19 @ 02:25:14</span
              ><span class="points-container"
                >Points: <span class="points">67</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=42179541"
                  >Comments</a
                ><span class="descendants">: 24</span></span
              >
            </h4>
          </section>
        </section>
        <section id="42179467">
          <h3>
            <a class="item" href="https://www.maslowcnc.com"
              >Maslow 4: Large format CNC routing made accessible</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-11-19 @ 02:09:27</span
              ><span class="points-container"
                >Points: <span class="points">162</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=42179467"
                  >Comments</a
                ><span class="descendants">: 43</span></span
              >
            </h4>
          </section>
        </section>
        <section id="42177767">
          <h3>
            <a
              class="item"
              href="https://www.bloomberg.com/news/articles/2024-11-18/doj-will-push-google-to-sell-off-chrome-to-break-search-monopoly"
              >DOJ will push Google to sell off Chrome</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-11-18 @ 22:24:07</span
              ><span class="points-container"
                >Points: <span class="points">734</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=42177767"
                  >Comments</a
                ><span class="descendants">: 856</span></span
              >
            </h4>
          </section>
        </section>
        <section id="42177619">
          <h3>
            <a
              class="item"
              href="https://reason.com/2024/11/18/how-scientific-americans-departing-editor-helped-degrade-science/"
              >Scientific American's departing editor and the politicization of
              science</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-11-18 @ 22:04:54</span
              ><span class="points-container"
                >Points: <span class="points">167</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=42177619"
                  >Comments</a
                ><span class="descendants">: 200</span></span
              >
            </h4>
          </section>
        </section>
        <section id="42177462">
          <h3>
            <a class="item" href="https://github.com/sharkdp/hyperfine"
              >Hyperfine: A command-line benchmarking tool</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-11-18 @ 21:47:36</span
              ><span class="points-container"
                >Points: <span class="points">162</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=42177462"
                  >Comments</a
                ><span class="descendants">: 28</span></span
              >
            </h4>
          </section>
        </section>
        <section id="42175316">
          <h3>
            <a
              class="item"
              href="https://abdisalan.com/posts/tragedy-running-old-node-project/"
              >The tragedy of running an old Node project</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-11-18 @ 18:24:21</span
              ><span class="points-container"
                >Points: <span class="points">135</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=42175316"
                  >Comments</a
                ><span class="descendants">: 187</span></span
              >
            </h4>
          </section>
        </section>
        <section id="42175023">
          <h3>
            <a
              class="item"
              href="https://blog.google/outreach-initiatives/education/google-scholar-20-years/"
              >20 years of Google Scholar</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-11-18 @ 18:01:18</span
              ><span class="points-container"
                >Points: <span class="points">333</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=42175023"
                  >Comments</a
                ><span class="descendants">: 146</span></span
              >
            </h4>
          </section>
        </section>
        <section id="42174829">
          <h3>
            <a
              class="item"
              href="https://github.com/circlemind-ai/fast-graphrag"
              >Show HN: FastGraphRAG – Better RAG using good old PageRank</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-11-18 @ 17:43:13</span
              ><span class="points-container"
                >Points: <span class="points">350</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=42174829"
                  >Comments</a
                ><span class="descendants">: 87</span></span
              >
            </h4>
            <div class="text">
              <p>
                Building a good RAG pipeline these days takes a lot of manual
                optimizations. Most engineers intuitively start from naive RAG:
                throw everything in a vector database and hope that semantic
                search is powerful enough. This can work for use cases where
                accuracy isn’t too important and hallucinations are tolerable,
                but it doesn’t work for more difficult queries that involve
                multi-hop reasoning or more advanced domain understanding. Also,
                it’s impossible to debug it.
              </p>
              <p>
                To address these limitations, many engineers find themselves
                adding extra layers like agent-based preprocessing, custom
                embeddings, reranking mechanisms, and hybrid search strategies.
                Much like the early days of machine learning when we manually
                crafted feature vectors to squeeze out marginal gains, building
                an effective RAG system often becomes an exercise in crafting
                engineering “hacks.”
              </p>
              <p>
                Earlier this year, Microsoft seeded the idea of using Knowledge
                Graphs for RAG and published GraphRAG - i.e. RAG with Knowledge
                Graphs. We believe that there is an incredible potential in this
                idea, but existing implementations are naive in the way they
                create and explore the graph. That’s why we developed Fast
                GraphRAG with a new algorithmic approach using good old
                PageRank.
              </p>
              <p>
                There are two main challenges when building a reliable RAG
                system:
              </p>
              <p>
                (1) Data Noise: Real-world data is often messy. Customer support
                tickets, chat logs, and other conversational data can include a
                lot of irrelevant information. If you push noisy data into a
                vector database, you’re likely to get noisy results.
              </p>
              <p>
                (2) Domain Specialization: For complex use cases, a RAG system
                must understand the domain-specific context. This requires
                creating representations that capture not just the words but the
                deeper relationships and structures within the data.
              </p>
              <p>
                Our solution builds on these insights by incorporating knowledge
                graphs into the RAG pipeline. Knowledge graphs store entities
                and their relationships, and can help structure data in a way
                that enables more accurate and context-aware information
                retrieval. 12 years ago Google announced the knowledge graph we
                all know about [1]. It was a pioneering move. Now we have LLMs,
                meaning that people can finally do RAG on their own data with
                tools that can be as powerful as Google’s original idea.
              </p>
              <p>
                Before we built this, Antonio was at Amazon, while Luca and
                Yuhang were finishing their PhDs at Oxford. We had been thinking
                about this problem for years and we always loved the parallel
                between pagerank and the human memory [2]. We believe that
                searching for memories is incredibly similar to searching the
                web.
              </p>
              <p>Here’s how it works:</p>
              <p>
                - Entity and Relationship Extraction: Fast GraphRAG uses LLMs to
                extract entities and their relationships from your data and
                stores them in a graph format [3].
              </p>
              <p>
                - Query Processing: When you make a query, Fast GraphRAG starts
                by finding the most relevant entities using vector search, then
                runs a personalized PageRank algorithm to determine the most
                important “memories” or pieces of information related to the
                query [4].
              </p>
              <p>
                - Incremental Updates: Unlike other graph-based RAG systems,
                Fast GraphRAG natively supports incremental data insertions.
                This means you can continuously add new data without
                reprocessing the entire graph.
              </p>
              <p>
                - Faster: These design choices make our algorithm faster and
                more affordable to run than other graph-based RAG systems
                because we eliminate the need for communities and clustering.
              </p>
              <p>
                Suppose you’re analyzing a book and want to focus on character
                interactions, locations, and significant events:
              </p>
              <p></p>
              <pre><code>  from fast_graphrag import GraphRAG
  
  DOMAIN = "Analyze this story and identify the characters. Focus on how they interact with each other, the locations they explore, and their relationships."
  
  EXAMPLE_QUERIES = [
      "What is the significance of Christmas Eve in A Christmas Carol?",
      "How does the setting of Victorian London contribute to the story's themes?",
      "Describe the chain of events that leads to Scrooge's transformation.",
      "How does Dickens use the different spirits (Past, Present, and Future) to guide Scrooge?",
      "Why does Dickens choose to divide the story into \"staves\" rather than chapters?"
  ]
  
  ENTITY_TYPES = ["Character", "Animal", "Place", "Object", "Activity", "Event"]
  
  grag = GraphRAG(
      working_dir="./book_example",
      domain=DOMAIN,
      example_queries="\n".join(EXAMPLE_QUERIES),
      entity_types=ENTITY_TYPES
  )
  
  with open("./book.txt") as f:
      grag.insert(f.read())
  
  print(grag.query("Who is Scrooge?").response)
</code></pre>
              This code creates a domain-specific knowledge graph based on your
              data, example queries, and specified entity types. Then you can
              query it in plain English while it automatically handles all the
              data fetching, entity extractions, co-reference resolutions,
              memory elections, etc. When you add new data, locking and
              checkpointing is handled for you as well.
              <p>
                This is the kind of infrastructure that GenAI apps need to
                handle large-scale real-world data. Our goal is to give you this
                infrastructure so that you can focus on what’s important:
                building great apps for your users without having to care about
                manually engineering a retrieval pipeline. In the managed
                service, we also have a suite of UI tools for you to explore and
                debug your knowledge graph.
              </p>
              <p>
                We have a free hosted solution with up to 100 monthly requests.
                When you’re ready to grow, we have paid plans that scale with
                you. And of course you can self host our open-source engine.
              </p>
              <p>
                Give us a spin today at
                <a href="https://circlemind.co">https://circlemind.co</a> and
                see our code at
                <a href="https://github.com/circlemind-ai/fast-graphrag"
                  >https://github.com/circlemind-ai/fast-graphrag</a
                >
              </p>
              <p>We’d love feedback :)</p>
              <p>
                [1]
                <a
                  href="https://blog.google/products/search/introducing-knowledge-graph-things-not/"
                  >https://blog.google/products/search/introducing-knowledge-gr...</a
                >
              </p>
              <p>
                [2] Griffiths, T. L., Steyvers, M., &amp; Firl, A. (2007).
                Google and the Mind: Predicting Fluency with PageRank.
                Psychological Science, 18(12), 1069–1076.
                <a href="http://www.jstor.org/stable/40064705"
                  >http://www.jstor.org/stable/40064705</a
                >
              </p>
              <p>
                [3] Similarly to Microsoft’s GraphRAG:
                <a href="https://github.com/microsoft/graphrag"
                  >https://github.com/microsoft/graphrag</a
                >
              </p>
              <p>
                [4] Similarly to OSU’s HippoRAG:
                <a href="https://github.com/OSU-NLP-Group/HippoRAG"
                  >https://github.com/OSU-NLP-Group/HippoRAG</a
                >
              </p>
              <p>
                <a href="https://vhs.charm.sh/vhs-4fCicgsbsc7UX0pemOcsMp.gif"
                  >https://vhs.charm.sh/vhs-4fCicgsbsc7UX0pemOcsMp.gif</a
                >
              </p>
            </div>
          </section>
        </section>
        <section id="42174231">
          <h3>
            <a class="item" href="https://mailcatcher.me/"
              >MailCatcher runs a super simple SMTP server</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-11-18 @ 16:51:29</span
              ><span class="points-container"
                >Points: <span class="points">249</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=42174231"
                  >Comments</a
                ><span class="descendants">: 76</span></span
              >
            </h4>
          </section>
        </section>
        <section id="42174204">
          <h3>
            <a class="item" href="https://news.ycombinator.com/item?id=42174204"
              >Launch HN: Regatta Storage (YC F24) – Turn S3 into a local-like,
              POSIX cloud FS</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-11-18 @ 16:49:09</span
              ><span class="points-container"
                >Points: <span class="points">476</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=42174204"
                  >Comments</a
                ><span class="descendants">: 245</span></span
              >
            </h4>
            <div class="text">
              <a href="https://regattastorage.com">https://regattastorage.com</a
              >). Regatta Storage is a new cloud file system that provides
              unlimited pay-as-you-go capacity, local-like performance, and
              automatic synchronization to S3-compatible storage. For example,
              you can use Regatta to instantly access massive data sets in S3
              with Spark, Pytorch, or pandas without paying for large, local
              disks or waiting for the data to download.
              <p>
                Check out an overview of how the service works here:
                <a href="https://www.youtube.com/watch?v=xh1q5p7E4JY"
                  >https://www.youtube.com/watch?v=xh1q5p7E4JY</a
                >, and you can try it for free at
                <a href="https://regattastorage.com"
                  >https://regattastorage.com</a
                >
                after signing up for an account. We wanted to let you try it
                without an account, but we figured that “Hacker News shares a
                file system and S3 bucket” wouldn’t be the best experience for
                the community.
              </p>
              <p>
                I built Regatta after spending nearly a decade building and
                operating at-scale cloud storage at places like Amazon’s Elastic
                File System (EFS) and Netflix. During my 8 years at EFS, I
                learned a lot about how teams thought about their storage usage.
                Users frequently told me that they loved how simple and scalable
                EFS was, and -- like S3 -- they didn’t have to guess how much
                capacity they needed up front.
              </p>
              <p>
                When I got to Netflix, I was surprised that there wasn’t more
                usage of EFS. If you looked around, it seemed like a natural
                fit. Every application needed a POSIX file system. Lots of
                applications had unclear or spikey storage needs. Often,
                developers wanted their storage to last beyond the lifetime of
                an individual instance or container. In fact, if you looked
                across all Netflix applications, some ridiculous amount of money
                was being spent on <i>empty storage space</i> because each of
                these local drives had to be overprovisioned for potential
                usage.
              </p>
              <p>
                However, in many cases, EFS wasn’t the perfect choice for these
                workloads. Moving workloads from local disks to NFS often
                encountered performance issues. Further, applications which
                treated their local disks as ephemeral would have to manually
                “clean up” left over data in a persistent storage system.
              </p>
              <p>
                At this point, I realized that there was a missing solution in
                the cloud storage market which wasn’t being filled by either
                block or file storage, and I decided to build Regatta.
              </p>
              <p>
                Regatta is a pay-as-you-go cloud file system that automatically
                expands with your application. Because it automatically
                synchronizes with S3 using native file formats, you can connect
                it to existing data sets and use recently written file data
                directly from S3. When data isn’t actively being used, it’s
                removed from the Regatta cache, so you only pay for the backing
                S3 storage. Finally, we’re developing a custom file protocol
                which allows us to achieve local-like performance for small-file
                workloads <i>and</i> Lustre-like scale-out performance for
                distributed data jobs.
              </p>
              <p>
                Under the hood, customers mount a Regatta file system by
                connecting to our fleet of caching instances over NFSv3 (soon,
                our custom protocol). Our instances then connect to the
                customer’s S3 bucket on the backend, and provide sub-millisecond
                cached-read and write performance. This durable cache allows us
                to provide a strongly consistent, efficient view of the file
                system to all connected file clients. We can perform challenging
                operations (like directory renaming) quickly and durably, while
                they asynchronously propagate to the S3 bucket.
              </p>
              <p>
                We’re excited to see users share our vision for Regatta. We have
                teams who are using us to build totally serverless Jupyter
                notebook servers for their AI researchers who prefer to upload
                and share data using the S3 web UI. We have teams who are using
                us as a distributed caching layer on top of S3 for low-latency
                access to common files. We have teams who are replacing their
                thin-provisioned Ceph boot volumes with Regatta for significant
                savings. We can’t wait to see what other things people will
                build and we hope you’ll give us a try at regattastorage.com.
              </p>
              <p>
                We’d love to get any early feedback from the community, ideas
                for future direction, or experiences in this space. I’ll be in
                the comments for the next few hours to respond!
              </p>
            </div>
          </section>
        </section>
        <section id="42173233">
          <h3>
            <a
              class="item"
              href="https://www.joshtumath.uk/posts/2024-11-08-how-a-bbc-navigation-bar-component-broke-depending-on-which-external-monitor-it-was-on/"
              >A BBC navigation bar component broke depending on the external
              monitor</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-11-18 @ 15:28:57</span
              ><span class="points-container"
                >Points: <span class="points">265</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=42173233"
                  >Comments</a
                ><span class="descendants">: 110</span></span
              >
            </h4>
          </section>
        </section>
        <section id="42173114">
          <h3>
            <a
              class="item"
              href="https://jvernay.fr/en/blog/skyline-2d-packer/implementation/"
              >The Skyline algorithm for packing 2D rectangles</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-11-18 @ 15:19:05</span
              ><span class="points-container"
                >Points: <span class="points">199</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=42173114"
                  >Comments</a
                ><span class="descendants">: 47</span></span
              >
            </h4>
          </section>
        </section>
        <section id="42172565">
          <h3>
            <a
              class="item"
              href="https://www.cnn.com/2024/11/18/europe/undersea-cable-disrupted-germany-finland-intl/index.html"
              >Two undersea cables in Baltic Sea disrupted</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-11-18 @ 14:31:17</span
              ><span class="points-container"
                >Points: <span class="points">352</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=42172565"
                  >Comments</a
                ><span class="descendants">: 607</span></span
              >
            </h4>
          </section>
        </section>
        <section id="42170519">
          <h3>
            <a class="item" href="https://github.com/notrab/dumbo"
              >Show HN: Dumbo – Hono inspired framework for PHP</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-11-18 @ 07:37:16</span
              ><span class="points-container"
                >Points: <span class="points">60</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=42170519"
                  >Comments</a
                ><span class="descendants">: 49</span></span
              >
            </h4>
            <div class="text">
              <p>
                In true JavaScript fashion, I decided to learn PHP again by
                building a framework to put all the pieces together in my brain.
              </p>
              <p>
                I absolutely love Hono.dev, and decided to base the PHP
                framework on that. Dumbo isn't intended to compete with Laravel,
                Symphony or Slim, if anything, it's something people can use in
                production, but also contribute to and be used as a learning
                resource for others.
              </p>
            </div>
          </section>
        </section>
        <section id="42168503">
          <h3>
            <a class="item" href="https://museumofbadart.org/"
              >Museum of Bad Art</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-11-18 @ 00:09:20</span
              ><span class="points-container"
                >Points: <span class="points">180</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=42168503"
                  >Comments</a
                ><span class="descendants">: 129</span></span
              >
            </h4>
          </section>
        </section>
        <section id="42146699">
          <h3>
            <a
              class="item"
              href="https://kidswholovemath.substack.com/p/its-hard-to-stop-math-acceleration"
              >It's hard to stop Math Acceleration once you start</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-11-15 @ 13:24:38</span
              ><span class="points-container"
                >Points: <span class="points">83</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=42146699"
                  >Comments</a
                ><span class="descendants">: 84</span></span
              >
            </h4>
          </section>
        </section>
        <section id="42136817">
          <h3>
            <a
              class="item"
              href="https://www.flightglobal.com/safety/uk-air-traffic-system-failure-triggered-by-misidentified-french-bee-flightplan-waypoint/157386.article"
              >Air traffic failure caused by two locations 3600nm apart sharing
              3-letter code</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-11-14 @ 15:04:57</span
              ><span class="points-container"
                >Points: <span class="points">232</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=42136817"
                  >Comments</a
                ><span class="descendants">: 237</span></span
              >
            </h4>
          </section>
        </section>
        <section id="42122557">
          <h3>
            <a
              class="item"
              href="https://awadwatt.com/tezoatlipoca/rim-job-blackberry-tales-the-story-of-sumit-b"
              >Rim/Blackberry tales – reply all</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-11-13 @ 03:18:44</span
              ><span class="points-container"
                >Points: <span class="points">49</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=42122557"
                  >Comments</a
                ><span class="descendants">: 18</span></span
              >
            </h4>
          </section>
        </section>
        <section id="42109382">
          <h3>
            <a
              class="item"
              href="https://www.theguardian.com/stage/2024/nov/11/magic-circle-tries-to-track-down-first-female-member-who-posed-as-a-man"
              >Magic Circle tries to track down first female member – who posed
              as a man</a
            >
          </h3>
          <section>
            <h4>
              <span>2024-11-11 @ 18:36:35</span
              ><span class="points-container"
                >Points: <span class="points">24</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=42109382"
                  >Comments</a
                ><span class="descendants">: 34</span></span
              >
            </h4>
          </section>
        </section>
      </section>
      <section id="archives">
        <h2>
          <a
            href="https://github.com/kherrick/hacker-news/blob/main/archives/index.md"
            >Archives</a
          >
        </h2>
        <section>
          <h3>
            <a
              href="https://github.com/kherrick/hacker-news/blob/main/archives/2024/index.md"
              >2024</a
            >
          </h3>
        </section>
        <section>
          <h3>
            <a
              href="https://github.com/kherrick/hacker-news/blob/main/archives/2023/index.md"
              >2023</a
            >
          </h3>
        </section>
        <section>
          <h3>
            <a
              href="https://github.com/kherrick/hacker-news/blob/main/archives/2022/index.md"
              >2022</a
            >
          </h3>
        </section>
      </section>
    </main>
    <script type="module">
      import { buildDescendants } from "./lib/build-html-descendants.js";
      import { buildNextItem } from "./lib/build-html-next-item.js";
      import { getNextDateTime } from "./lib/date-time.js";

      const updateSectionById = (id) =>
        fetch(`https://hacker-news.firebaseio.com/v0/item/${id}.json`).then(
          (result) =>
            result.json().then(({ descendants, id, score, text, type }) => {
              const currentItem = document.getElementById(id);

              if (score) {
                currentItem.querySelector(".points").textContent = score;
              }

              if (descendants && (type === "poll" || type === "story")) {
                const currentDescendants =
                  currentItem.querySelector(".descendants");

                if (currentDescendants) {
                  currentDescendants.textContent = `: ${descendants}`;
                } else {
                  const comments = buildDescendants(
                    document,
                    descendants,
                    `https://news.ycombinator.com/item?id=${id}`
                  );

                  currentItem.querySelector("h4").appendChild(comments);
                }
              }

              if (text) {
                const currentText = currentItem.querySelector(".text");

                if (currentText) {
                  currentText.innerHTML = text.replace(/\0/g, "");
                } else {
                  const content = document.createElement("div");
                  content.innerHTML = text.replace(/\0/g, "");
                  content.setAttribute("class", "text");

                  currentItem.appendChild(content);
                }
              }
            })
        );

      class UpdateQueue {
        constructor() {
          this._ids = [];
          this._isUpdating = false;
        }

        addItemById(id) {
          this._ids.push(id);
        }

        async flush() {
          const id = this._ids.shift();

          if (id) {
            this._isUpdating = true;

            await updateSectionById(id);
            await this.flush();
          } else {
            this._isUpdating = false;

            setTimeout(async () => {
              if (!this._isUpdating && this._ids && this._ids.length) {
                await this.flush();
              }
            }, 0);
          }
        }
      }

      // get latest data
      const latestSection = document.getElementById("latest");

      for (let item of latestSection.querySelectorAll("section[id]")) {
        updateSectionById(item.getAttribute("id"));
      }

      if ("IntersectionObserver" in window) {
        window.hackerNewsState = { index: [], nextTimeIndex: -1 };

        const addNewsItem = async (newsItem, queue) => {
          try {
            const { date, time, itemComments, itemTitle, itemLink } = newsItem;
            const section = await buildNextItem({
              document,
              dateTime: `${date}, ${time}`,
              itemComments,
              itemLink,
              itemTitle: new DOMParser().parseFromString(
                itemTitle.replace(/\\/g, ""),
                "text/html"
              ).documentElement.textContent,
              fetchItemDetails: false,
            });

            // display loading indicator for section
            section.querySelector(".points-container").innerHTML =
              'Points: <span class="points"><img style="height: 100%;" src="lib/images/loading.svg" /></span>';

            const id = section.getAttribute("id");
            if (!document.getElementById(id)) {
              document.getElementById("latest").appendChild(section);

              queue.addItemById(id);
            }
          } catch (error) {}
        };

        const buildArchiveIndex = async (lastDateTime) => {
          const nextDate = lastDateTime.slice(0, 10);
          const nextYear = nextDate.slice(0, 4);

          return (
            await (
              await fetch(
                `https://raw.githubusercontent.com/kherrick/hacker-news/main/archives/${nextYear}/${nextDate}/index.md`
              )
            ).text()
          )
            .split("\n")
            .filter((line) => line.match(new RegExp("^\\* \\[")))
            .map((line) => {
              const segment = line.replace("* ", "").split("](");
              const pubDate = segment[0].slice(1);

              const itemComments = segment[1].split(") - [")[0];
              const itemTitle = segment[1].split(") - [")[1];
              const itemLink = segment[2].slice(0, -1);
              const date = pubDate.slice(0, 10);
              const time = pubDate.slice(-8);

              return {
                date,
                itemComments,
                itemLink,
                itemTitle,
                time,
              };
            });
        };

        const handleIntersectingEntry = async (entry, queue) => {
          if (entry.isIntersecting) {
            const lastDateTime = document
              .getElementById("latest")
              .querySelector(
                "section:last-child > section > h4 > span"
              ).textContent;

            const nextDateTime = getNextDateTime(lastDateTime ?? "", -1);
            const archiveIndex = await buildArchiveIndex(nextDateTime);
            const nextTimeIndex = archiveIndex.findIndex(
              ({ time }) => time === nextDateTime.slice(-8)
            );

            const handleIndexUpdate = (index, existingIndexValues = []) => {
              index.forEach((i) => {
                existingIndexValues.push(i);
              });
              return existingIndexValues;
            };

            window.hackerNewsState = {
              index: handleIndexUpdate(
                archiveIndex,
                window.hackerNewsState.index
              ),
              nextTimeIndex,
            };

            let currentTimeIndex = nextTimeIndex + 1;
            const items = Object.values(window.hackerNewsState.index);
            for (let item of items) {
              if (currentTimeIndex < window.hackerNewsState.index.length) {
                addNewsItem(items[currentTimeIndex], queue);

                currentTimeIndex = currentTimeIndex + 1;
              }
            }

            queue.flush();
          }
        };

        const archives = document.getElementById("archives");
        const archivesObserver = new IntersectionObserver(
          (entries) => {
            const queue = new UpdateQueue();

            entries.forEach((entry) => handleIntersectingEntry(entry, queue));
          },
          {
            root: null,
            rootMargin: "0px",
            threshold: 0,
          }
        );

        archivesObserver.observe(archives);

        let latestSectionsExpanded = true;
        const handleLatestHeaderClick = () => {
          latestSectionsExpanded = !latestSectionsExpanded;

          if (latestSectionsExpanded) {
            archivesObserver.observe(archives);
          } else {
            archivesObserver.disconnect(archives);
          }

          for (let section of document.querySelectorAll("#latest > section")) {
            section.style.display = latestSectionsExpanded ? "block" : "none";
          }
        };

        const latestHeader = document.querySelector("#latest > h2");
        latestHeader.style.cursor = "pointer";
        latestHeader.addEventListener("click", handleLatestHeaderClick);
      }
    </script>
    <script type="module">
      import { Workbox } from "https://storage.googleapis.com/workbox-cdn/releases/6.4.1/workbox-window.prod.mjs";

      if ("serviceWorker" in navigator) {
        const base = document.querySelector("base");
        const serviceWorkerPath = `${
          base ? base.href.replace(/\/$/, "") : ""
        }/service-worker.js`;

        const wb = new Workbox(serviceWorkerPath);

        // setup event listeners
        wb.addEventListener("waiting", (event) => {
          wb.addEventListener("controlling", () => {
            window.location.reload();
          });

          wb.messageSkipWaiting();
        });

        wb.register();
      }
    </script>
  </body>
</html>
