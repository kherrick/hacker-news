<!DOCTYPE html>
<html lang="en" xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <meta
      content="width=device-width, initial-scale=1.0, viewport-fit=cover"
      name="viewport"
    />
    <meta name="description" content="Hacker News" />
    <meta name="theme-color" content="#fff" />
    <title>Hacker News</title>
    <link rel="manifest" href="manifest.json" />
    <link
      href="data:image/x-icon;base64,AAABAAEAAQECAAEAAQA4AAAAFgAAACgAAAABAAAAAgAAAAEAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAAEAAQECAAEAAQA4AAAAFgAAACgAAAABAAAAAgAAAAEAAQAAAAAAAAAAAAAAAAAAAAAAAAAA"
      rel="icon"
      type="image/x-icon"
    />
    <link
      href="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAgAAAAIAAQMAAADOtka5AAAAA1BMVEUAAACnej3aAAAANklEQVR42u3BAQEAAACCIP+vbkhAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB8G4IAAAFjdVCkAAAAAElFTkSuQmCC"
      rel="apple-touch-icon"
    />
    <style>
      /*<!--*/
      body {
        color: rgb(25, 25, 25);
        font-family: Verdana, Geneva, sans-serif;
        margin: 0;
      }

      a {
        text-decoration: none;
      }

      a:link,
      a:focus,
      a:hover,
      a:active {
        color: rgb(75, 75, 125);
      }

      a:visited {
        color: rgb(25, 25, 25);
      }

      h1 > a,
      h1 > a:link,
      h1 > a:focus,
      h1 > a:hover,
      h1 > a:active,
      h1 > a:visited,
      h2 > a,
      h2 > a:link,
      h2 > a:focus,
      h2 > a:hover,
      h2 > a:active,
      h2 > a:visited {
        color: rgb(25, 25, 25);
      }

      h1 {
        background-color: rgb(255, 102, 0);
        margin: 0;
        padding: 1rem;
      }

      h2 {
        background-color: rgb(200, 200, 200);
        margin: 1rem 0;
        padding: 0.5rem 0.5rem 0.5rem 1rem;
      }

      #latest > section,
      #archives > section {
        margin: 0 1rem 1rem 1rem;
        padding-bottom: 1rem;
      }

      #latest > section:not(:last-child),
      #archives > section:not(:last-child) {
        border-bottom: 1px dotted rgb(200, 200, 200);
      }

      section > h3 {
        margin: 0 0 0.5rem 0;
      }

      section > h4 {
        font-weight: normal;
        margin: 0 0 0 1rem;
      }

      .descendants-container,
      .points-container {
        align-items: center;
        border-left: 1px solid #333;
        display: inline-flex;
        margin-left: 0.5rem;
        padding-left: 0.5rem;
        text-align: center;
      }

      .points {
        align-items: center;
        display: inline-flex;
        height: 1rem;
        margin-left: 1ch;
        min-width: 3ch;
      }

      .text {
        line-height: 1.5rem;
        margin: 1rem 1rem 0 1rem;
        overflow: auto;
      }

      .text > p:first-child {
        margin-top: 1rem;
      }

      .text > p:last-child {
        margin-bottom: 0;
      }
      /*-->*/
    </style>
  </head>

  <body>
    <main>
      <h1><a href="https://kherrick.github.io/hacker-news/">Hacker News</a></h1>
      <section id="latest">
        <h2>Latest</h2>
        <section id="44947276">
          <h3>
            <a
              class="item"
              href="https://jslegenddev.substack.com/p/how-to-start-making-games-in-javascript"
              >Starting game development in JavaScript with no experience</a
            >
          </h3>
          <section>
            <h4>
              <span>2025-08-19 @ 01:25:03</span
              ><span class="points-container"
                >Points: <span class="points">45</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=44947276"
                  >Comments</a
                ><span class="descendants">: 28</span></span
              >
            </h4>
          </section>
        </section>
        <section id="44946996">
          <h3>
            <a class="item" href="https://github.com/ClemensElflein/OpenMower"
              >OpenMower – An Open Source Lawn Mower</a
            >
          </h3>
          <section>
            <h4>
              <span>2025-08-19 @ 00:35:08</span
              ><span class="points-container"
                >Points: <span class="points">63</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=44946996"
                  >Comments</a
                ><span class="descendants">: 11</span></span
              >
            </h4>
          </section>
        </section>
        <section id="44946813">
          <h3>
            <a
              class="item"
              href="https://jonathanadams.pro/blog-articles/Nasa-Fortran-Code-1963.pdf"
              >A general Fortran code for solutions of problems in space
              mechanics [pdf]</a
            >
          </h3>
          <section>
            <h4>
              <span>2025-08-19 @ 00:12:17</span
              ><span class="points-container"
                >Points: <span class="points">24</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=44946813"
                  >Comments</a
                ><span class="descendants">: 5</span></span
              >
            </h4>
          </section>
        </section>
        <section id="44946783">
          <h3>
            <a
              class="item"
              href="https://www.binarly.io/blog/persistent-risk-xz-utils-backdoor-still-lurking-in-docker-images"
              >XZ Utils Backdoor Still Lurking in Docker Images</a
            >
          </h3>
          <section>
            <h4>
              <span>2025-08-19 @ 00:07:22</span
              ><span class="points-container"
                >Points: <span class="points">72</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=44946783"
                  >Comments</a
                ><span class="descendants">: 26</span></span
              >
            </h4>
          </section>
        </section>
        <section id="44946774">
          <h3>
            <a
              class="item"
              href="https://linch.substack.com/p/ted-chiang-review"
              >Ted Chiang: The Secret Third Thing</a
            >
          </h3>
          <section>
            <h4>
              <span>2025-08-19 @ 00:05:59</span
              ><span class="points-container"
                >Points: <span class="points">26</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=44946774"
                  >Comments</a
                ><span class="descendants">: 5</span></span
              >
            </h4>
          </section>
        </section>
        <section id="44946762">
          <h3>
            <a
              class="item"
              href="https://divernet.com/scuba-news/freediving/how-croatian-freediver-held-breath-for-29-minutes/"
              >Croatian freediver held breath for 29 minutes</a
            >
          </h3>
          <section>
            <h4>
              <span>2025-08-19 @ 00:04:11</span
              ><span class="points-container"
                >Points: <span class="points">119</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=44946762"
                  >Comments</a
                ><span class="descendants">: 40</span></span
              >
            </h4>
          </section>
        </section>
        <section id="44945966">
          <h3>
            <a
              class="item"
              href="https://coppolaemilio.com/entries/what-could-have-been/"
              >What could have been</a
            >
          </h3>
          <section>
            <h4>
              <span>2025-08-18 @ 22:29:44</span
              ><span class="points-container"
                >Points: <span class="points">120</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=44945966"
                  >Comments</a
                ><span class="descendants">: 100</span></span
              >
            </h4>
          </section>
        </section>
        <section id="44945959">
          <h3>
            <a
              class="item"
              href="https://www.smithsonianmag.com/smart-news/lab-grown-salmon-hits-the-menu-at-an-oregon-restaurant-as-the-fda-greenlights-the-cell-cultured-product-180986769/"
              >Lab-grown salmon hits the menu</a
            >
          </h3>
          <section>
            <h4>
              <span>2025-08-18 @ 22:29:14</span
              ><span class="points-container"
                >Points: <span class="points">99</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=44945959"
                  >Comments</a
                ><span class="descendants">: 156</span></span
              >
            </h4>
          </section>
        </section>
        <section id="44945783">
          <h3>
            <a class="item" href="https://fsantanna.github.io/sc.html"
              >Structured (Synchronous) Concurrency</a
            >
          </h3>
          <section>
            <h4>
              <span>2025-08-18 @ 22:02:15</span
              ><span class="points-container"
                >Points: <span class="points">22</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=44945783"
                  >Comments</a
                ><span class="descendants">: 1</span></span
              >
            </h4>
          </section>
        </section>
        <section id="44945730">
          <h3>
            <a class="item" href="https://www.newgrounds.com/bbs/topic/1542140"
              >Newgrounds: Flash Forward 2025</a
            >
          </h3>
          <section>
            <h4>
              <span>2025-08-18 @ 21:54:13</span
              ><span class="points-container"
                >Points: <span class="points">38</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=44945730"
                  >Comments</a
                ><span class="descendants">: 11</span></span
              >
            </h4>
          </section>
        </section>
        <section id="44945562">
          <h3>
            <a
              class="item"
              href="https://www.ycombinator.com/companies/spice-data/jobs/RJz1peY-product-associate-new-grad"
              >Spice Data (YC S19) Is Hiring a Product Associate (New Grad)</a
            >
          </h3>
          <section>
            <h4>
              <span>2025-08-18 @ 21:31:49</span
              ><span class="points-container"
                >Points: <span class="points">1</span></span
              >
            </h4>
          </section>
        </section>
        <section id="44945532">
          <h3>
            <a class="item" href="https://help.obsidian.md/bases"
              >Obsidian Bases</a
            >
          </h3>
          <section>
            <h4>
              <span>2025-08-18 @ 21:28:05</span
              ><span class="points-container"
                >Points: <span class="points">361</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=44945532"
                  >Comments</a
                ><span class="descendants">: 107</span></span
              >
            </h4>
          </section>
        </section>
        <section id="44945379">
          <h3>
            <a class="item" href="https://www.fractionaljobs.io"
              >Show HN: Fractional jobs – part-time roles for engineers</a
            >
          </h3>
          <section>
            <h4>
              <span>2025-08-18 @ 21:10:39</span
              ><span class="points-container"
                >Points: <span class="points">180</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=44945379"
                  >Comments</a
                ><span class="descendants">: 96</span></span
              >
            </h4>
            <div class="text">
              <p>So I built Fractional Jobs.</p>
              <p>
                The goal is to help more people break out of W2 life and into
                their own independent careers by helping them find great clients
                to work with.
              </p>
              <p>
                We find and vet the clients, and then engineers can request
                intros to any that seem like a good fit. We'll make the intro
                assuming the client opts in after seeing your profile.
              </p>
              <p>
                We have 9 open engineering roles right now: - 2x Fractional CTO
                - 2x AI engineers - 3x full-stack - 1x staff frontend - 1x
                mobile
              </p>
            </div>
          </section>
        </section>
        <section id="44945008">
          <h3>
            <a class="item" href="https://github.com/tiny-tpu-v2/tiny-tpu"
              >A minimal tensor processing unit (TPU), inspired by Google's
              TPU</a
            >
          </h3>
          <section>
            <h4>
              <span>2025-08-18 @ 20:34:37</span
              ><span class="points-container"
                >Points: <span class="points">100</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=44945008"
                  >Comments</a
                ><span class="descendants">: 2</span></span
              >
            </h4>
          </section>
        </section>
        <section id="44944592">
          <h3>
            <a class="item" href="https://www.tinytpu.com"
              >Show HN: I built a toy TPU that can do inference and training on
              the XOR problem</a
            >
          </h3>
          <section>
            <h4>
              <span>2025-08-18 @ 19:52:14</span
              ><span class="points-container"
                >Points: <span class="points">63</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=44944592"
                  >Comments</a
                ><span class="descendants">: 13</span></span
              >
            </h4>
            <div class="text">
              <p>
                - Building a chip for ML workloads seemed cool - There was no
                well-documented open source repo for an ML accelerator that
                performed both inference and training
              </p>
              <p>
                None of us have real professional experience in hardware design,
                which, in a way, made the TPU even more appealing since we
                weren't able to estimate exactly how difficult it would be. As
                we worked on the initial stages of this project, we established
                a strict design philosophy: TO ALWAYS TRY THE HACKY WAY. This
                meant trying out the "dumb" ideas that came to our mind first
                BEFORE consulting external sources. This philosophy helped us
                make sure we weren't reverse engineering the TPU, but rather
                re-inventing it, which helped us derive many of the key
                mechanisms used in the TPU ourselves.
              </p>
              <p>
                We also wanted to treat this project as an exercise to code
                without relying on AI to write for us, since we felt that our
                initial instinct recently has been to reach for llms whenever we
                faced a slight struggle. We wanted to cultivate a certain style
                of thinking that we could take forward with us and use in any
                future endeavours to think through difficult problems.
              </p>
              <p>
                Throughout this project we tried to learn as much as we could
                about the fundamentals of deep learning, hardware design and
                creating algorithms and we found that the best way to learn
                about this stuff is by drawing everything out and making that
                our first instinct. In tinytpu.com, you will see how our
                explanations were inspired by this philosophy.
              </p>
              <p>
                Note that this is NOT a 1-to-1 replica of the TPU--it is our
                attempt at re-inventing a toy version of it ourselves.
              </p>
            </div>
          </section>
        </section>
        <section id="44944291">
          <h3>
            <a
              class="item"
              href="https://arstechnica.com/tech-policy/2025/08/t-mobile-claimed-selling-location-data-without-consent-is-legal-judges-disagree/"
              >T-Mobile claimed selling location data without consent is
              legal–judges disagree</a
            >
          </h3>
          <section>
            <h4>
              <span>2025-08-18 @ 19:25:01</span
              ><span class="points-container"
                >Points: <span class="points">274</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=44944291"
                  >Comments</a
                ><span class="descendants">: 68</span></span
              >
            </h4>
          </section>
        </section>
        <section id="44943986">
          <h3>
            <a class="item" href="https://www.youtube.com/watch?v=sRPnX_f2V_c"
              >Show HN: We started building an AI dev tool but it turned into a
              Sims-style game</a
            >
          </h3>
          <section>
            <h4>
              <span>2025-08-18 @ 18:51:23</span
              ><span class="points-container"
                >Points: <span class="points">103</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=44943986"
                  >Comments</a
                ><span class="descendants">: 58</span></span
              >
            </h4>
            <div class="text">
              <a href="https://www.theinterface.com/"
                >https://www.theinterface.com/</a
              >).
              <p>
                We started out building an AI agent dev tool, but somewhere
                along the way it turned into Sims for AI agents.
              </p>
              <p>
                Demo video:
                <a href="https://www.youtube.com/watch?v=sRPnX_f2V_c"
                  >https://www.youtube.com/watch?v=sRPnX_f2V_c</a
                >.
              </p>
              <p>
                The original idea was simple: make it easy to create AI agents.
                We started with Jupyter Notebooks, where each cell could be
                callable by MCP—so agents could turn them into tools for
                themselves. It worked well enough that the system became
                self-improving, churning out content, and acting like a co-pilot
                that helped you build new agents.
              </p>
              <p>
                But when we stepped back, what we had was these endless walls of
                text. And even though it worked, honestly, it was just boring.
                We were also convinced that it would be swallowed up by the next
                model’s capabilities. We wanted to build something
                else—something that made AI less of a black box and more
                engaging. Why type into a chat box all day if you could look
                your agents in the face, see their confusion, and watch when and
                how they interact?
              </p>
              <p>
                Both of us grew up on simulation games—RollerCoaster Tycoon 3,
                Age of Empires, SimCity—so we started experimenting with running
                LLM agents inside a 3D world. At first it was pure curiosity,
                but right away, watching agents interact in real time was much
                more interesting than anything we’d done before.
              </p>
              <p>
                The very first version was small: a single Unity room, an MCP
                server, and a chat box. Even getting two agents to take turns
                took weeks. Every run surfaced quirks—agents refusing to talk at
                all, or only “speaking” by dancing or pulling facial expressions
                to show emotion. That unpredictability kept us building.
              </p>
              <p>
                Now it’s a desktop app (Tauri + Unity via WebGL) where humans
                and agents share 3D tile-based rooms. Agents receive structured
                observations every tick and can take actions that change the
                world. You can edit the rules between runs—prompts, decision
                logic, even how they see chat history—without rebuilding.
              </p>
              <p>
                On the technical side, we built a Unity bridge with MCP and
                multi-provider routing via LiteLLM, with local model support via
                Mistral.rs coming next. All system prompts are editable, so you
                can directly experiment with coordination strategies—tuning how
                “chatty” agents are versus how much they move or manipulate the
                environment.
              </p>
              <p>
                We then added a tilemap editor so you can design custom rooms,
                set tile-based events with conditions and actions, and turn them
                into puzzles or hazards. There’s community sharing built in, so
                you can post rooms you make.
              </p>
              <p>
                Watching agents collude or negotiate through falling tiles,
                teleports, landmines, fire, “win” and “lose” tiles, and tool
                calls for things like lethal fires or disco floors is a much
                more fun way to spend our days.
              </p>
              <p>
                Under the hood, Unity’s ECS drives a whole state machine and
                event system. And because humans and AI share the same space in
                real time, every negotiation, success, or failure also becomes
                useful multi-agent, multimodal data for post-training or world
                models.
              </p>
              <p>
                Our early users are already using it for prompt-injection
                testing, social engineering scenarios, cooperative games, and
                model comparisons. The bigger vision is to build an open-ended,
                AI-native sim-game where you can build and interact with
                anything or anyone. You can design puzzles, levels, and
                environments, have agents compete or collaborate, set up games,
                or even replay your favorite TV shows.
              </p>
              <p>
                The fun part is that no two interactions are ever the same.
                Everything is emergent, not hard-coded, so the same level played
                six times will play out differently each time.
              </p>
              <p>
                The plan is to keep expanding—bigger rooms, more in-world tools
                for agents, and then multiplayer hosting. It’s live now, no
                waitlist. Free to play. You can bring your own API keys, or
                start with $10 in credits and run agents right away:
                www.TheInterface.com.
              </p>
              <p>
                We’d love feedback on scenarios worth testing and what to build
                next. Tell us the weird stuff you’d throw at this—we’ll be in
                the comments.
              </p>
            </div>
          </section>
        </section>
        <section id="44942936">
          <h3>
            <a class="item" href="https://graic.net/p/left-to-right-programming"
              >Left to Right Programming</a
            >
          </h3>
          <section>
            <h4>
              <span>2025-08-18 @ 17:08:36</span
              ><span class="points-container"
                >Points: <span class="points">221</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=44942936"
                  >Comments</a
                ><span class="descendants">: 198</span></span
              >
            </h4>
          </section>
        </section>
        <section id="44942731">
          <h3>
            <a
              class="item"
              href="https://github.com/epicenter-so/epicenter/tree/main/apps/whispering"
              >Show HN: Whispering – Open-source, local-first dictation you can
              trust</a
            >
          </h3>
          <section>
            <h4>
              <span>2025-08-18 @ 16:52:29</span
              ><span class="points-container"
                >Points: <span class="points">294</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=44942731"
                  >Comments</a
                ><span class="descendants">: 79</span></span
              >
            </h4>
            <div class="text">
              <p>
                I really like dictation. For years, I relied on transcription
                tools that were <i>almost</i> good, but they were all
                closed-source. Even a lot of them that claimed to be “local” or
                “on-device” were still black boxes that left me wondering where
                my audio really went.
              </p>
              <p>
                So I built Whispering. It’s open-source, local-first, and most
                importantly, transparent with your data. All your data is stored
                locally on your device. For me, the features were good enough
                that I left my paid tools behind (I used Superwhisper and Wispr
                Flow before).
              </p>
              <p>
                Productivity apps should be open-source and transparent with
                your data, but they also need to match the UX of paid,
                closed-software alternatives. I hope Whispering is near that
                point. I use it for several hours a day, from coding to thinking
                out loud while carrying pizza boxes back from the office.
              </p>
              <p>
                Here’s an overview:
                <a href="https://www.youtube.com/watch?v=1jYgBMrfVZs"
                  >https://www.youtube.com/watch?v=1jYgBMrfVZs</a
                >, and here’s how I personally am using it with Claude Code
                these days:
                <a href="https://www.youtube.com/watch?v=tpix588SeiQ"
                  >https://www.youtube.com/watch?v=tpix588SeiQ</a
                >.
              </p>
              <p>
                There are plenty of transcription apps out there, but I hope
                Whispering adds some extra competition from the OSS ecosystem
                (one of my other OSS favorites is Handy
                <a href="https://github.com/cjpais/Handy"
                  >https://github.com/cjpais/Handy</a
                >). Whispering has a few tricks up its sleeve, like a
                voice-activated mode for hands-free operation (no button
                holding), and customizable AI transformations with any
                prompt/model.
              </p>
              <p>
                Whispering used to be in my personal GH repo, but I recently
                moved it as part of a larger project called Epicenter (<a
                  href="https://github.com/epicenter-so/epicenter"
                  >https://github.com/epicenter-so/epicenter</a
                >), which I should explain a bit...
              </p>
              <p>
                I’m basically obsessed with local-first open-source software. I
                think there should be an open-source, local-first version of
                every app, and I would like them all to work together. The idea
                of Epicenter is to store your data in a folder of plaintext and
                SQLite, and build a suite of interoperable, local-first tools on
                top of this shared memory. Everything is totally transparent, so
                you can trust it.
              </p>
              <p>
                Whispering is the first app in this effort. It’s not there yet
                regarding memory, but it’s getting there. I’ll probably write
                more about the bigger picture soon, but mainly I just want to
                make software and let it speak for itself (no pun intended in
                this case!), so this is my Show HN for now.
              </p>
              <p>
                I just finished college and was about to move back with my
                parents and work on this instead of getting a job…and then I
                somehow got into YC. So my current plan is to cover my living
                expenses and use the YC funding to support maintainers, our
                dependencies, and people working on their own open-source
                local-first projects. More on that soon.
              </p>
              <p>
                Would love your feedback, ideas, and roasts. If you would like
                to support the project, star it on GitHub here (<a
                  href="https://github.com/epicenter-so/epicenter"
                  >https://github.com/epicenter-so/epicenter</a
                >) and join the Discord here (<a
                  href="https://go.epicenter.so/discord"
                  >https://go.epicenter.so/discord</a
                >). Everything’s MIT licensed, so fork it, break it, ship your
                own version, copy whatever you want!
              </p>
            </div>
          </section>
        </section>
        <section id="44942501">
          <h3>
            <a
              class="item"
              href="https://annas-archive.org/blog/an-update-from-the-team.html"
              >Anna's Archive: An Update from the Team</a
            >
          </h3>
          <section>
            <h4>
              <span>2025-08-18 @ 16:31:48</span
              ><span class="points-container"
                >Points: <span class="points">820</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=44942501"
                  >Comments</a
                ><span class="descendants">: 383</span></span
              >
            </h4>
          </section>
        </section>
        <section id="44941580">
          <h3>
            <a class="item" href="https://www.realitydefender.com/platform/api"
              >Launch HN: Reality Defender (YC W22) – API for Deepfake and GenAI
              Detection</a
            >
          </h3>
          <section>
            <h4>
              <span>2025-08-18 @ 15:16:34</span
              ><span class="points-container"
                >Points: <span class="points">71</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=44941580"
                  >Comments</a
                ><span class="descendants">: 33</span></span
              >
            </h4>
            <div class="text">
              <a href="https://www.realitydefender.com"
                >https://www.realitydefender.com</a
              >). We build real-time multimodal and multi-model deepfake
              detection for Fortune 100s and governments all over the world. (We
              even won the RSAC Innovation Showcase award for our work:
              <a
                href="https://www.prnewswire.com/news-releases/reality-defender-wins-most-innovative-startup-at-rsa-conference-2024-innovation-sandbox-302137326.html"
                >https://www.prnewswire.com/news-releases/reality-defender-wi...</a
              >)
              <p>
                Today, we’re excited to share our public API and SDK, allowing
                anyone to access our platform with 2 lines of code:
                <a href="https://www.realitydefender.com/api"
                  >https://www.realitydefender.com/api</a
                >
              </p>
              <p>
                Back in W22, we launched our product to detect AI-generated
                media across audio, video, and images:
                <a href="https://news.ycombinator.com/item?id=30766050"
                  >https://news.ycombinator.com/item?id=30766050</a
                >
              </p>
              <p>
                That post kicked off conversations with devs, security teams,
                researchers, and governments. The most common question: "Can we
                get API/SDK access to build deepfake detection into our
                product?"
              </p>
              <p>
                We’ve heard that from solo devs building moderation tools,
                fintechs adding ID verification, founders running marketplaces,
                and infrastructure companies protecting video calls and
                onboarding flows. They weren’t asking us to build anything new;
                they simply wanted access to what we already had so they could
                plug it in and move forward.
              </p>
              <p>
                After running pilots and engagements with customers, we’re
                finally ready to share our public API and SDK. Now anyone can
                embed deepfake detection with just two lines of code, starting
                at the low price of free.
              </p>
              <p>
                <a href="https://www.realitydefender.com/api"
                  >https://www.realitydefender.com/api</a
                >
              </p>
              <p>
                Our new developer tools support detection across images, voice,
                video, and text — with the former two available as part of the
                free tier. If your product touches KYC, UGC, support workflows,
                communications, marketplaces, or identity layers, you can now
                embed real-time detection directly in your stack. It runs in the
                cloud, and longstanding clients using our platform have also
                deployed on-prem, at the edge, or on fully airgapped systems.
              </p>
              <p>
                SDKs are currently available in Python, Java, Rust, TypeScript,
                and Go. The first 50 scans per month are free, with usage-based
                pricing beyond that. If you’re working on something that
                requires other features or streaming access (like real-time
                voice or video), email us directly at yc@realitydefender.com
              </p>
              <p>
                Much has changed since 2022. The threats we imagined back then
                are now showing up in everyday support tickets and incident
                reports. We’ve witnessed voice deepfakes targeting bank call
                centers to commit real-time fraud; fabricated documents and
                AI-generated selfies slip through KYC and IDV onboarding
                systems; fake dating profiles, AI-generated marketplace sellers,
                and “verified” influencers impersonating real people. Political
                disinformation videos and synthetic media leaks have triggered
                real-world legal and PR crises. Even reviews, support
                transcripts, and impersonation scripts are increasingly being
                generated by AI. Detection remains harder than we first expected
                since we began in 2021. New generation methods emerge every few
                weeks that invalidate prior assumptions. This is why we are
                committed to building every layer of this ourselves. We don’t
                license or white-label detection models; everything we deploy is
                built in-house by our team.
              </p>
              <p>
                Since our original launch, we’ve worked with tier-one banks,
                global governments, and media companies to deploy detection
                inside their highest-risk workflows. However, we always believed
                the need wasn’t limited to large institutions, but everywhere.
                It showed up in YC office hours, in early bug reports, and in
                group chats after our last HN post.
              </p>
              <p>
                We’ve taken our time to make sure this was built well, flexible
                enough for startups, and battle-tested enough to trust in
                production. The API you can use today is the same one powering
                many of our enterprise deployments.
              </p>
              <p>
                Our goal is to make Reality Defender feel like Stripe, Twilio,
                or Plaid — an invisible, trusted layer that you can drop into
                your system to protect what matters. We feel deepfake detection
                is a key component of critical infrastructure, and like any good
                infrastructure, it should be modular, reliable, and boring (in
                the best possible way).
              </p>
              <p>
                Reality Defender is already in the Zoom marketplace and will be
                on the Teams marketplace soon. We will also power deepfake
                detection for identity workflows, support platforms, and
                internal trust and safety pipelines.
              </p>
              <p>
                If you're building something where trust, identity, or content
                integrity matter, or if you’ve run into weird edge cases you
                can’t explain, we’d love to hear from you.
              </p>
              <p>
                You can get started here:
                <a href="https://realitydefender.com/api"
                  >https://realitydefender.com/api</a
                >
              </p>
              <p>Or you can try us for free two different ways:</p>
              <p>
                1) 1-click add to Zoom / Teams to try in your own calls
                immediately.
              </p>
              <p>
                2) Email us up to 50 files at yc@realitydefender.com and we’ll
                scan them for you — no setup required.
              </p>
              <p>
                Thanks again to the HN community for helping launch us three
                years ago. It’s been a wild ride, and we’re excited to share
                something new. We live on HN ourselves and will be here for all
                your feedback. Let us know what you think!
              </p>
            </div>
          </section>
        </section>
        <section id="44941369">
          <h3>
            <a
              class="item"
              href="https://www.nytimes.com/2025/08/18/arts/counter-strike-half-life-minh-le.html"
              >Counter-Strike: A billion-dollar game built in a dorm room</a
            >
          </h3>
          <section>
            <h4>
              <span>2025-08-18 @ 14:59:26</span
              ><span class="points-container"
                >Points: <span class="points">244</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=44941369"
                  >Comments</a
                ><span class="descendants">: 208</span></span
              >
            </h4>
          </section>
        </section>
        <section id="44940485">
          <h3>
            <a class="item" href="https://github.com/FFmpeg/asm-lessons"
              >FFmpeg Assembly Language Lessons</a
            >
          </h3>
          <section>
            <h4>
              <span>2025-08-18 @ 13:39:53</span
              ><span class="points-container"
                >Points: <span class="points">322</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=44940485"
                  >Comments</a
                ><span class="descendants">: 94</span></span
              >
            </h4>
          </section>
        </section>
        <section id="44927778">
          <h3>
            <a
              class="item"
              href="https://jotunheimr.idlerpg.net/users/jotun/lawnmower/"
              >An IRC-Enabled Lawn Mower</a
            >
          </h3>
          <section>
            <h4>
              <span>2025-08-16 @ 23:48:35</span
              ><span class="points-container"
                >Points: <span class="points">64</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=44927778"
                  >Comments</a
                ><span class="descendants">: 9</span></span
              >
            </h4>
          </section>
        </section>
        <section id="44927629">
          <h3>
            <a
              class="item"
              href="https://www.freecodecamp.org/news/how-to-free-up-and-automatically-manage-disk-space-for-wsl-on-windows-1011/"
              >Free up space (effortlessly) on WSL2</a
            >
          </h3>
          <section>
            <h4>
              <span>2025-08-16 @ 23:15:25</span
              ><span class="points-container"
                >Points: <span class="points">15</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=44927629"
                  >Comments</a
                ><span class="descendants">: 10</span></span
              >
            </h4>
          </section>
        </section>
        <section id="44926855">
          <h3>
            <a
              class="item"
              href="https://www.popsci.com/technology/tibetan-prayer-scroll-scans/"
              >X-ray scans reveal Buddhist prayers inside tiny Tibetan
              scrolls</a
            >
          </h3>
          <section>
            <h4>
              <span>2025-08-16 @ 20:54:54</span
              ><span class="points-container"
                >Points: <span class="points">67</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=44926855"
                  >Comments</a
                ><span class="descendants">: 5</span></span
              >
            </h4>
          </section>
        </section>
        <section id="44923520">
          <h3>
            <a class="item" href="https://scrollguard.app/"
              >Show HN: I built an app to block Shorts and Reels</a
            >
          </h3>
          <section>
            <h4>
              <span>2025-08-16 @ 14:01:38</span
              ><span class="points-container"
                >Points: <span class="points">502</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=44923520"
                  >Comments</a
                ><span class="descendants">: 196</span></span
              >
            </h4>
            <div class="text">
              <p>
                Most screen time apps I found focus on blocking the app itself
                instead of the addictive feed, so I created this app to allow me
                to keep using the "healthy" and "social" features and block the
                infinite scrolling (Reels)
              </p>
              <p>
                After implementing the block on Instagram Reels, I got addicted
                to YouTube Shorts and Reddit feed. So, I extended the app to
                cover these as well.
              </p>
              <p>
                To avoid replacing the scrolling for regular feeds, I also added
                a feature that shows a pop-up when I'm overscrolling in any app.
                It forces me to stop and think for a minute before I continue
                scrolling.
              </p>
              <p>
                I built it on Android Studio, using Kotlin and Jetpack Compose
                for the UI. I use the Accessibility Service to detect scrolls
                and navigate out of them. Unfortunately, this only works for
                Android. There is no way (as far as I know) to do this on iOS.
              </p>
              <p>I'd love to hear your thoughts</p>
            </div>
          </section>
        </section>
        <section id="44921780">
          <h3>
            <a
              class="item"
              href="https://5wgraphicsblog.com/2016/10/24/the-cutaway-illustrations-of-fred-freeman/"
              >The Cutaway Illustrations of Fred Freeman (2016)</a
            >
          </h3>
          <section>
            <h4>
              <span>2025-08-16 @ 09:41:57</span
              ><span class="points-container"
                >Points: <span class="points">75</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=44921780"
                  >Comments</a
                ><span class="descendants">: 9</span></span
              >
            </h4>
          </section>
        </section>
        <section id="44915228">
          <h3>
            <a
              class="item"
              href="https://phys.org/news/2025-07-precision-tracks-woody-great-plains.html"
              >Precision mapping tracks woody plant spread across Great Plains
              grasslands</a
            >
          </h3>
          <section>
            <h4>
              <span>2025-08-15 @ 17:39:24</span
              ><span class="points-container"
                >Points: <span class="points">12</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=44915228"
                  >Comments</a
                ><span class="descendants">: 2</span></span
              >
            </h4>
          </section>
        </section>
        <section id="44907133">
          <h3>
            <a
              class="item"
              href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5242171"
              >The Rising Returns to R&amp;amp;D: Ideas Are Not Getting Harder
              to Find</a
            >
          </h3>
          <section>
            <h4>
              <span>2025-08-14 @ 23:58:12</span
              ><span class="points-container"
                >Points: <span class="points">70</span></span
              ><span class="descendants-container"
                ><a href="https://news.ycombinator.com/item?id=44907133"
                  >Comments</a
                ><span class="descendants">: 14</span></span
              >
            </h4>
          </section>
        </section>
      </section>
      <section id="archives">
        <h2>
          <a
            href="https://github.com/kherrick/hacker-news/blob/main/archives/index.md"
            >Archives</a
          >
        </h2>
        <section>
          <h3>
            <a
              href="https://github.com/kherrick/hacker-news/blob/main/archives/2025/index.md"
              >2025</a
            >
          </h3>
        </section>
        <section>
          <h3>
            <a
              href="https://github.com/kherrick/hacker-news/blob/main/archives/2024/index.md"
              >2024</a
            >
          </h3>
        </section>
        <section>
          <h3>
            <a
              href="https://github.com/kherrick/hacker-news/blob/main/archives/2023/index.md"
              >2023</a
            >
          </h3>
        </section>
        <section>
          <h3>
            <a
              href="https://github.com/kherrick/hacker-news/blob/main/archives/2022/index.md"
              >2022</a
            >
          </h3>
        </section>
      </section>
    </main>
    <script type="module">
      import { buildDescendants } from "./lib/build-html-descendants.js";
      import { buildNextItem } from "./lib/build-html-next-item.js";
      import { getNextDateTime } from "./lib/date-time.js";

      const updateSectionById = (id) =>
        fetch(`https://hacker-news.firebaseio.com/v0/item/${id}.json`).then(
          (result) =>
            result.json().then(({ descendants, id, score, text, type }) => {
              const currentItem = document.getElementById(id);

              if (score) {
                currentItem.querySelector(".points").textContent = score;
              }

              if (descendants && (type === "poll" || type === "story")) {
                const currentDescendants =
                  currentItem.querySelector(".descendants");

                if (currentDescendants) {
                  currentDescendants.textContent = `: ${descendants}`;
                } else {
                  const comments = buildDescendants(
                    document,
                    descendants,
                    `https://news.ycombinator.com/item?id=${id}`
                  );

                  currentItem.querySelector("h4").appendChild(comments);
                }
              }

              if (text) {
                const currentText = currentItem.querySelector(".text");

                if (currentText) {
                  currentText.innerHTML = text.replace(/\0/g, "");
                } else {
                  const content = document.createElement("div");
                  content.innerHTML = text.replace(/\0/g, "");
                  content.setAttribute("class", "text");

                  currentItem.appendChild(content);
                }
              }
            })
        );

      class UpdateQueue {
        constructor() {
          this._ids = [];
          this._isUpdating = false;
        }

        addItemById(id) {
          this._ids.push(id);
        }

        async flush() {
          const id = this._ids.shift();

          if (id) {
            this._isUpdating = true;

            await updateSectionById(id);
            await this.flush();
          } else {
            this._isUpdating = false;

            setTimeout(async () => {
              if (!this._isUpdating && this._ids && this._ids.length) {
                await this.flush();
              }
            }, 0);
          }
        }
      }

      // get latest data
      const latestSection = document.getElementById("latest");

      for (let item of latestSection.querySelectorAll("section[id]")) {
        updateSectionById(item.getAttribute("id"));
      }

      if ("IntersectionObserver" in window) {
        window.hackerNewsState = { index: [], nextTimeIndex: -1 };

        const addNewsItem = async (newsItem, queue) => {
          try {
            const { date, time, itemComments, itemTitle, itemLink } = newsItem;
            const section = await buildNextItem({
              document,
              dateTime: `${date}, ${time}`,
              itemComments,
              itemLink,
              itemTitle: new DOMParser().parseFromString(
                itemTitle.replace(/\\/g, ""),
                "text/html"
              ).documentElement.textContent,
              fetchItemDetails: false,
            });

            // display loading indicator for section
            section.querySelector(".points-container").innerHTML =
              'Points: <span class="points"><img style="height: 100%;" src="lib/images/loading.svg" /></span>';

            const id = section.getAttribute("id");
            if (!document.getElementById(id)) {
              document.getElementById("latest").appendChild(section);

              queue.addItemById(id);
            }
          } catch (error) {}
        };

        const buildArchiveIndex = async (lastDateTime) => {
          const nextDate = lastDateTime.slice(0, 10);
          const nextYear = nextDate.slice(0, 4);

          return (
            await (
              await fetch(
                `https://raw.githubusercontent.com/kherrick/hacker-news/main/archives/${nextYear}/${nextDate}/index.md`
              )
            ).text()
          )
            .split("\n")
            .filter((line) => line.match(new RegExp("^\\* \\[")))
            .map((line) => {
              const segment = line.replace("* ", "").split("](");
              const pubDate = segment[0].slice(1);

              const itemComments = segment[1].split(") - [")[0];
              const itemTitle = segment[1].split(") - [")[1];
              const itemLink = segment[2].slice(0, -1);
              const date = pubDate.slice(0, 10);
              const time = pubDate.slice(-8);

              return {
                date,
                itemComments,
                itemLink,
                itemTitle,
                time,
              };
            });
        };

        const handleIntersectingEntry = async (entry, queue) => {
          if (entry.isIntersecting) {
            const lastDateTime = document
              .getElementById("latest")
              .querySelector(
                "section:last-child > section > h4 > span"
              ).textContent;

            const nextDateTime = getNextDateTime(lastDateTime ?? "", -1);
            const archiveIndex = await buildArchiveIndex(nextDateTime);
            const nextTimeIndex = archiveIndex.findIndex(
              ({ time }) => time === nextDateTime.slice(-8)
            );

            const handleIndexUpdate = (index, existingIndexValues = []) => {
              index.forEach((i) => {
                existingIndexValues.push(i);
              });
              return existingIndexValues;
            };

            window.hackerNewsState = {
              index: handleIndexUpdate(
                archiveIndex,
                window.hackerNewsState.index
              ),
              nextTimeIndex,
            };

            let currentTimeIndex = nextTimeIndex + 1;
            const items = Object.values(window.hackerNewsState.index);
            for (let item of items) {
              if (currentTimeIndex < window.hackerNewsState.index.length) {
                addNewsItem(items[currentTimeIndex], queue);

                currentTimeIndex = currentTimeIndex + 1;
              }
            }

            queue.flush();
          }
        };

        const archives = document.getElementById("archives");
        const archivesObserver = new IntersectionObserver(
          (entries) => {
            const queue = new UpdateQueue();

            entries.forEach((entry) => handleIntersectingEntry(entry, queue));
          },
          {
            root: null,
            rootMargin: "0px",
            threshold: 0,
          }
        );

        archivesObserver.observe(archives);

        let latestSectionsExpanded = true;
        const handleLatestHeaderClick = () => {
          latestSectionsExpanded = !latestSectionsExpanded;

          if (latestSectionsExpanded) {
            archivesObserver.observe(archives);
          } else {
            archivesObserver.disconnect(archives);
          }

          for (let section of document.querySelectorAll("#latest > section")) {
            section.style.display = latestSectionsExpanded ? "block" : "none";
          }
        };

        const latestHeader = document.querySelector("#latest > h2");
        latestHeader.style.cursor = "pointer";
        latestHeader.addEventListener("click", handleLatestHeaderClick);
      }
    </script>
    <script type="module">
      import { Workbox } from "https://storage.googleapis.com/workbox-cdn/releases/6.4.1/workbox-window.prod.mjs";

      if ("serviceWorker" in navigator) {
        const base = document.querySelector("base");
        const serviceWorkerPath = `${
          base ? base.href.replace(/\/$/, "") : ""
        }/service-worker.js`;

        const wb = new Workbox(serviceWorkerPath);

        // setup event listeners
        wb.addEventListener("waiting", (event) => {
          wb.addEventListener("controlling", () => {
            window.location.reload();
          });

          wb.messageSkipWaiting();
        });

        wb.register();
      }
    </script>
  </body>
</html>
